{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement game logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class GoGame:\n",
    "    \"\"\"\n",
    "    Go game class.\n",
    "    This class implements the Go game logic to be used for training the neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self, board_size=19) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the Go game with the given board size.\n",
    "        Args:\n",
    "            board_size (int): Size of the Go board (default is 19).\n",
    "        \"\"\"\n",
    "        self.board_size = board_size\n",
    "        self.board = torch.zeros((board_size, board_size), dtype=torch.float32)\n",
    "\n",
    "    def place_stone(self, x, y, color) -> None:\n",
    "        \"\"\"\n",
    "        Places a stone of the specified color at the given position (x, y) on the board.\n",
    "        Args:\n",
    "            x (float): X-coordinate of the position.\n",
    "            y (float): Y-coordinate of the position.\n",
    "            color (float): Color of the stone (1 for black, -1 for white).\n",
    "        \"\"\"\n",
    "        self.board[x][y] = color\n",
    "        self.remove_dead_stones(-color)\n",
    "\n",
    "    def has_liberties(self, board, x, y, color, visited=None) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if a stone at a given position has liberties.\n",
    "        Args:\n",
    "            board (torch.Tensor): Current game board.\n",
    "            x (float): X-coordinate of the position.\n",
    "            y (float): Y-coordinate of the position.\n",
    "            color (float): Color of the stone (1 for black, -1 for white).\n",
    "            visited (set): Set of visited positions to avoid infinite recursion (default is None).\n",
    "        Returns:\n",
    "            bool: True if the stone has liberties, False otherwise.\n",
    "        \"\"\"\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        if (x, y) in visited:\n",
    "            return False\n",
    "        visited.add((x, y))\n",
    "\n",
    "        if x < 0 or x >= len(board) or y < 0 or y >= len(board[0]):\n",
    "            return False\n",
    "        if board[x][y] == 0:\n",
    "            return True\n",
    "        if board[x][y] != color:\n",
    "            return False\n",
    "\n",
    "        # Recursive check for liberties in adjacent positions\n",
    "        liberties = any(\n",
    "            self.has_liberties(board, x + dx, y + dy, color, visited) for dx, dy in [(1, 0), (-1, 0), (0, 1), (0, -1)]\n",
    "        )\n",
    "        return liberties\n",
    "\n",
    "    def remove_dead_stones(self, color) -> None:\n",
    "        \"\"\"\n",
    "        Removes dead stones of the specified color from the board.\n",
    "        Args:\n",
    "            color (float): Color of the stones to be removed (1 for black, -1 for white).\n",
    "        \"\"\"\n",
    "        dead_stones = []\n",
    "        for x in range(self.board_size):\n",
    "            for y in range(self.board_size):\n",
    "                if self.board[x][y] == color and not self.has_liberties(self.board, x, y, color):\n",
    "                    dead_stones.append((x, y))\n",
    "\n",
    "        # Remove dead stones from the board\n",
    "        for x, y in dead_stones:\n",
    "            self.board[x][y] = 0\n",
    "\n",
    "    def get_board(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the current game board.\n",
    "        Returns:\n",
    "            torch.Tensor: Current game board.\n",
    "        \"\"\"\n",
    "        return self.board\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"\n",
    "        Resets the game board to the initial state.\n",
    "        \"\"\"\n",
    "        self.board = torch.zeros(\n",
    "            (self.board_size, self.board_size), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define dataset for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class GoDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        Initializes the GoDataset with the given CSV file path.\n",
    "        Args:\n",
    "            path (str): Path to the CSV file containing Go game data.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.goGame = GoGame()\n",
    "        self.char2idx = {c: i for i, c in enumerate('abcdefghijklmnopqrs')}\n",
    "\n",
    "        # Load data from CSV file\n",
    "        with open(self.path, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',')\n",
    "            # Read row by row\n",
    "            self.data = list(reader)\n",
    "            # Discard the label and player turn information, calculate the max sequence length\n",
    "            self.max_sequence_length = max([len(row) for row in self.data]) - 2\n",
    "\n",
    "    def _step(self, step):\n",
    "        \"\"\"\n",
    "        Perform a step in the game based on the given input step.\n",
    "        Args:\n",
    "            step (str): A str containing player, x-coordinate, and y-coordinate information.\n",
    "        \"\"\"\n",
    "        current_player = -1 if step[0] == 'B' else 1\n",
    "        x = self.char2idx[step[2]]\n",
    "        y = self.char2idx[step[3]]\n",
    "        self.goGame.place_stone(x, y, current_player)\n",
    "\n",
    "    def _transform(self, data):\n",
    "        \"\"\"\n",
    "        Transform data from CSV file into a list of padded boards.\n",
    "        Args:\n",
    "            data (list): List of steps in the game.\n",
    "        Returns:\n",
    "            torch.Tensor: Transformed and padded data.\n",
    "        \"\"\"\n",
    "        transformed_data = []\n",
    "        for i in range(2, len(data)):\n",
    "            self._step(data[i])\n",
    "            transformed_data.append(self.goGame.get_board().clone())\n",
    "\n",
    "        # Pad the data to the maximum sequence length with a very large negative value\n",
    "        padded_data = torch.full(\n",
    "            (self.max_sequence_length, 19, 19), -1e9, dtype=torch.float32)\n",
    "        for i in range(len(transformed_data)):\n",
    "            padded_data[i, :, :] = transformed_data[i]\n",
    "\n",
    "        return padded_data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        Returns:\n",
    "            int: Number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get data at the given index.\n",
    "        Args:\n",
    "            idx (int): Index of the data sample.\n",
    "        Returns:\n",
    "            torch.Tensor: Processed and padded data sample.\n",
    "        \"\"\"\n",
    "        # Get data at the given index\n",
    "        row = self.data[idx]\n",
    "\n",
    "        # Transform data into a board\n",
    "        self.goGame.reset()\n",
    "        processed_data = self._transform(row)\n",
    "        return processed_data\n",
    "\n",
    "\n",
    "goDataset = GoDataset('data/train/dan_train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def draw_board(board):\n",
    "    \"\"\"\n",
    "    Draws the Go board with stones based on the provided board configuration.\n",
    "    Args:\n",
    "        board (numpy.ndarray): 2D array representing the Go board (-1 for black stones, 1 for white stones, 0 for empty).\n",
    "    Returns:\n",
    "        numpy.ndarray: RGB image of the Go board with stones and grid lines.\n",
    "    \"\"\"\n",
    "    # Create an RGB image (3 channels) with a green background\n",
    "    image = np.ones((20*20, 20*20, 3), dtype=np.uint8) * \\\n",
    "        173  # RGB value for green\n",
    "\n",
    "    # Draw lines for the board grid\n",
    "    for i in range(1, 20):\n",
    "        cv2.line(image, (i * 20, 20), (i * 20, 20*20 - 20),\n",
    "                 color=(0, 0, 0), thickness=1)\n",
    "        cv2.line(image, (20, i * 20), (20*20 - 20, i * 20),\n",
    "                 color=(0, 0, 0), thickness=1)\n",
    "\n",
    "    black = (0, 0, 0)  # RGB for black\n",
    "    white = (255, 255, 255)  # RGB for white\n",
    "    # Draw stones on the board\n",
    "    for row in range(19):\n",
    "        for col in range(19):\n",
    "            if board[row][col] == -1:  # Black stone\n",
    "                cv2.circle(image, (col * 20 + 20, row * 20 + 20),\n",
    "                           8, black, -1)  # Draw a filled circle\n",
    "            elif board[row][col] == 1:  # White stone\n",
    "                cv2.circle(image, (col * 20 + 20, row * 20 + 20),\n",
    "                           8, white, -1)  # Draw a filled circle\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def save_as_video(boards):\n",
    "    \"\"\"\n",
    "    Saves a sequence of Go board states as a video file.\n",
    "    Args:\n",
    "        boards (list): List of 2D numpy arrays representing Go board states.\n",
    "    \"\"\"\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for video format (MP4)\n",
    "    # VideoWriter(filename, codec, fps, frameSize)\n",
    "    video = cv2.VideoWriter('test.mp4', fourcc, 10,\n",
    "                            (20*20, 20*20))  # VideoWriter object\n",
    "\n",
    "    # Iterate through the list of board states and save them as frames in the video\n",
    "    for board in boards:\n",
    "        image = draw_board(board)  # Convert board state to an RGB image\n",
    "        video.write(image)  # Write the image as a frame in the video\n",
    "\n",
    "    # Release the VideoWriter object, finalizing the video creation\n",
    "    video.release()\n",
    "\n",
    "\n",
    "# boards = goDataset.__getitem__(0)\n",
    "# save_as_video(boards)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PredEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PredEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    PredNet encoder module.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        num_channels (int): number of depthwise convolution layer input channels.\n",
    "        depthwise_kernel_size (int): kernel size of depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
    "        bias (bool, optional): indicates whether to add bias term to each convolution layer. (Default: ``False``)\n",
    "        use_group_norm (bool, optional): use GroupNorm rather than BatchNorm. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        num_channels: int,\n",
    "        depthwise_kernel_size: int,\n",
    "        dropout: float = 0.0,\n",
    "        bias: bool = False,\n",
    "        use_group_norm: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if (depthwise_kernel_size - 1) % 2 != 0:\n",
    "            raise ValueError(\n",
    "                \"depthwise_kernel_size must be odd to achieve 'SAME' padding.\")\n",
    "\n",
    "        # Layer normalization for input\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "\n",
    "        # Sequential layers: 1x1 Conv, GLU, Depthwise Conv, Normalization, Activation, 1x1 Conv, Dropout\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                input_dim,\n",
    "                2 * num_channels,\n",
    "                1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.GLU(dim=1),\n",
    "            nn.Conv1d(\n",
    "                num_channels,\n",
    "                num_channels,\n",
    "                depthwise_kernel_size,\n",
    "                stride=1,\n",
    "                padding=(depthwise_kernel_size - 1) // 2,\n",
    "                groups=num_channels,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.GroupNorm(num_groups=1, num_channels=num_channels)\n",
    "            if use_group_norm\n",
    "            else nn.BatchNorm1d(num_channels),\n",
    "            nn.SiLU(),  # SiLU activation function (Sigmoid Linear Unit)\n",
    "            nn.Conv1d(\n",
    "                num_channels,\n",
    "                input_dim,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Conformer convolution module.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor with shape `(B, D)`.\n",
    "            B: Batch size, D: Input dimension\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with shape `(B, D)`.\n",
    "        \"\"\"\n",
    "        # input: (B, D) -> (B, 1, D)\n",
    "        x = input.unsqueeze(1)\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        # x: (B, 1, D) -> (B, D, 1)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.sequential(x)\n",
    "\n",
    "        return x.squeeze(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Conformer convolution module.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        num_channels (int): number of depthwise convolution layer input channels.\n",
    "        depthwise_kernel_size (int): kernel size of depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
    "        bias (bool, optional): indicates whether to add bias term to each convolution layer. (Default: ``False``)\n",
    "        use_group_norm (bool, optional): use GroupNorm rather than BatchNorm. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        num_channels: int,\n",
    "        depthwise_kernel_size: int,\n",
    "        dropout: float = 0.0,\n",
    "        bias: bool = False,\n",
    "        use_group_norm: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if (depthwise_kernel_size - 1) % 2 != 0:\n",
    "            raise ValueError(\n",
    "                \"depthwise_kernel_size must be odd to achieve 'SAME' padding.\")\n",
    "\n",
    "        # Layer normalization for input\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "\n",
    "        # Sequential layers: 1x1 Conv, GLU, Depthwise Conv, Normalization, Activation, 1x1 Conv, Dropout\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                input_dim,\n",
    "                2 * num_channels,\n",
    "                1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.GLU(dim=1),\n",
    "            nn.Conv1d(\n",
    "                num_channels,\n",
    "                num_channels,\n",
    "                depthwise_kernel_size,\n",
    "                stride=1,\n",
    "                padding=(depthwise_kernel_size - 1) // 2,\n",
    "                groups=num_channels,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.GroupNorm(num_groups=1, num_channels=num_channels)\n",
    "            if use_group_norm\n",
    "            else nn.BatchNorm1d(num_channels),\n",
    "            nn.SiLU(),  # SiLU activation function (Sigmoid Linear Unit)\n",
    "            nn.Conv1d(\n",
    "                num_channels,\n",
    "                input_dim,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Conformer convolution module.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor with shape `(B, T, D)`.\n",
    "            B: Batch size, T: Sequence length, D: Input dimension\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with shape `(B, T, D)`.\n",
    "        \"\"\"\n",
    "        x = self.layer_norm(input)\n",
    "        # Transpose to shape `(B, D, T)` for 1D convolutions\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.sequential(x)  # Apply sequential layers\n",
    "        return x.transpose(1, 2)  # Transpose back to shape `(B, T, D)`\n",
    "\n",
    "\n",
    "class FeedForwardModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Feedforward module with Layer Normalization, Linear layers, SiLU activation, and Dropout.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Input dimension.\n",
    "        hidden_dim (int): Hidden layer dimension.\n",
    "        dropout (float, optional): Dropout probability. (Default: 0.1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
    "        super(FeedForwardModule, self).__init__()\n",
    "        self.module = nn.Sequential(\n",
    "            nn.LayerNorm(input_dim),\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),  # SiLU activation function (Sigmoid Linear Unit)\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the FeedForwardModule.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape `(B, T, D)`.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with the same shape as the input tensor.\n",
    "        \"\"\"\n",
    "        return self.module(x)\n",
    "\n",
    "\n",
    "class ConformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Conformer layer that constitutes Conformer.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        ffn_dim (int): hidden layer dimension of the feedforward network.\n",
    "        num_attention_heads (int): number of attention heads.\n",
    "        depthwise_conv_kernel_size (int): kernel size of the depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
    "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
    "            in the convolution module. (Default: ``False``)\n",
    "        convolution_first (bool, optional): apply the convolution module ahead of\n",
    "            the attention module. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            ffn_dim,\n",
    "            num_attention_heads,\n",
    "            depthwise_conv_kernel_size,\n",
    "            dropout=0.1,\n",
    "            use_group_norm=False,\n",
    "            convolution_first=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ffn1 = FeedForwardModule(input_dim, ffn_dim, dropout)\n",
    "        self.ffn2 = FeedForwardModule(input_dim, ffn_dim, dropout)\n",
    "        self.conv = ConvModule(\n",
    "            input_dim,\n",
    "            input_dim,\n",
    "            depthwise_conv_kernel_size,\n",
    "            dropout,\n",
    "            use_group_norm=use_group_norm,\n",
    "        )\n",
    "        self.self_attn = nn.MultiheadAttention(\n",
    "            input_dim, num_attention_heads, dropout=dropout\n",
    "        )\n",
    "        self.self_attn_dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "        self.convolution_first = convolution_first\n",
    "\n",
    "    def apply_conv(self, x):\n",
    "        \"\"\"\n",
    "        Apply the convolution module.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape `(T, B, D)`.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after applying the convolution module.\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        # Transpose to shape `(B, T, D)` for 1D convolutions\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(0, 1)  # Transpose back to shape `(T, B, D)`\n",
    "        x = x + residual\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the ConformerBlock.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape `(T, B, D)`.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with the same shape as the input tensor.\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        x = self.ffn1(x)  # First feedforward module\n",
    "        x = 0.5 * x + residual  # Residual connection and scaling\n",
    "\n",
    "        if self.convolution_first:\n",
    "            x = self.apply_conv(x)  # Apply convolution module if specified\n",
    "\n",
    "        residual = x\n",
    "        x = self.layer_norm(x)  # Layer normalization\n",
    "        x, _ = self.self_attn(x, x, x)  # Multihead self-attention\n",
    "        x = self.self_attn_dropout(x)\n",
    "        x = x + residual  # Residual connection\n",
    "\n",
    "        if not self.convolution_first:\n",
    "            x = self.apply_conv(x)  # Apply convolution module if specified\n",
    "\n",
    "        residual = x\n",
    "        x = self.ffn2(x)  # Second feedforward module\n",
    "        x = 0.5 * x + residual  # Residual connection and scaling\n",
    "        x = self.layer_norm(x)  # Final layer normalization\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        num_heads (int): number of attention heads in each Conformer layer.\n",
    "        ffn_dim (int): hidden layer dimension of feedforward networks.\n",
    "        num_layers (int): number of Conformer layers to instantiate.\n",
    "        depthwise_conv_kernel_size (int): kernel size of each Conformer layer's depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
    "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
    "            in the convolution module. (Default: ``False``)\n",
    "        convolution_first (bool, optional): apply the convolution module ahead of\n",
    "            the attention module. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            num_heads,\n",
    "            ffn_dim,\n",
    "            num_layers,\n",
    "            depthwise_conv_kernel_size,\n",
    "            dropout=0.1,\n",
    "            use_group_norm=False,\n",
    "            convolution_first=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Instantiate Conformer blocks\n",
    "        self.conformer_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ConformerBlock(\n",
    "                    input_dim,\n",
    "                    ffn_dim,\n",
    "                    num_heads,\n",
    "                    depthwise_conv_kernel_size,\n",
    "                    dropout,\n",
    "                    use_group_norm,\n",
    "                    convolution_first,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the Generator (Conformer model).\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): input with shape `(B, T, input_dim)`.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: output with shape `(B, T, input_dim)`.\n",
    "        \"\"\"\n",
    "        batch_size, seq_length, _, _ = x.shape\n",
    "        x = x.view(batch_size, seq_length, -1)  # Flatten input tensor\n",
    "\n",
    "        x = x.transpose(0, 1)  # Transpose to shape `(T, B, input_dim)`\n",
    "\n",
    "        # Pass input through Conformer blocks\n",
    "        for layer in self.conformer_blocks:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = x.transpose(0, 1)  # Transpose back to shape `(B, T, input_dim)`\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Model: Conformer\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        output_dim (int): output dimension.\n",
    "        num_heads (int): number of attention heads in each Conformer layer.\n",
    "        ffn_dim (int): hidden layer dimension of feedforward networks.\n",
    "        num_layers (int): number of Conformer layers to instantiate.\n",
    "        depthwise_conv_kernel_size (int): kernel size of each Conformer layer's depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
    "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
    "            in the convolution module. (Default: ``False``)\n",
    "        convolution_first (bool, optional): apply the convolution module ahead of\n",
    "            the attention module. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            output_dim,\n",
    "            num_heads,\n",
    "            ffn_dim,\n",
    "            num_layers,\n",
    "            depthwise_conv_kernel_size,\n",
    "            dropout=0.1,\n",
    "            use_group_norm=False,\n",
    "            convolution_first=False,\n",
    "    ):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Instantiate the Conformer module\n",
    "        self.conformer = Conformer(\n",
    "            input_dim,\n",
    "            num_heads,\n",
    "            ffn_dim,\n",
    "            num_layers,\n",
    "            depthwise_conv_kernel_size,\n",
    "            dropout,\n",
    "            use_group_norm,\n",
    "            convolution_first,\n",
    "        )\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the Generator (Conformer model).\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): input with shape `(B, T, input_dim)`.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: output with shape `(B, output_dim)`.\n",
    "        \"\"\"\n",
    "        input_copy = torch.clone(x)\n",
    "\n",
    "        # Pass the input through the Conformer layers\n",
    "        conformer_output = self.conformer(x)\n",
    "\n",
    "        # Reshape the output for the linear layer\n",
    "        B, T, D = conformer_output.shape\n",
    "        reshaped_output = conformer_output.reshape(B, T * D)\n",
    "\n",
    "        # Apply linear transformation\n",
    "        linear_output = nn.Linear(\n",
    "            reshaped_output.shape[1], self.output_dim)(reshaped_output)\n",
    "        # Apply log softmax activation\n",
    "        output = nn.LogSoftmax(dim=1)(linear_output)\n",
    "\n",
    "        return output, input_copy\n",
    "\n",
    "\n",
    "height, width = 19, 19\n",
    "\n",
    "gen = Generator(\n",
    "    input_dim=height * width,\n",
    "    output_dim=height * width,\n",
    "    num_heads=1,\n",
    "    ffn_dim=8,\n",
    "    num_layers=6,\n",
    "    depthwise_conv_kernel_size=3,\n",
    "    dropout=0.1,\n",
    "    use_group_norm=False,\n",
    "    convolution_first=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Model: Conformer, PredEncoder\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension for Conformer.\n",
    "        height (int): height of the input for PredEncoder.\n",
    "        width (int): width of the input for PredEncoder.\n",
    "        num_heads (int): number of attention heads in each Conformer layer.\n",
    "        ffn_dim (int): hidden layer dimension of feedforward networks in Conformer.\n",
    "        num_layers (int): number of Conformer layers to instantiate.\n",
    "        depthwise_conv_kernel_size (int): kernel size of each Conformer layer's depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
    "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
    "            in the convolution module. (Default: ``False``)\n",
    "        convolution_first (bool, optional): apply the convolution module ahead of\n",
    "            the attention module. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            height,\n",
    "            width,\n",
    "            num_heads,\n",
    "            ffn_dim,\n",
    "            num_layers,\n",
    "            depthwise_conv_kernel_size,\n",
    "            dropout=0.1,\n",
    "            use_group_norm=False,\n",
    "            convolution_first=False,\n",
    "    ):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # Instantiate the Generator (Conformer) module\n",
    "        self.generator = Generator(\n",
    "            input_dim,\n",
    "            height * width,\n",
    "            num_heads,\n",
    "            ffn_dim,\n",
    "            num_layers,\n",
    "            depthwise_conv_kernel_size,\n",
    "            dropout,\n",
    "            use_group_norm,\n",
    "            convolution_first,\n",
    "        )\n",
    "\n",
    "        # Instantiate the PredEncoder module\n",
    "        self.pred_encoder = PredEncoder(\n",
    "            input_dim=height * width,\n",
    "            num_channels=height * width,\n",
    "            depthwise_kernel_size=3,\n",
    "            bias=False,\n",
    "            use_group_norm=False,\n",
    "        )\n",
    "\n",
    "        # Linear layers for final classification\n",
    "        self.linear = nn.Sequential(\n",
    "            # Concatenate Conformer output and PredEncoder output\n",
    "            nn.Linear(2 * (height * width), height),\n",
    "            nn.Linear(height, 2)  # Output 2 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Forward pass of the Discriminator.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): input with shape `(B, T, input_dim)` (for Conformer).\n",
    "            y (torch.Tensor): input with shape `(B, height * width)` (for PredEncoder).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: output with shape `(B, 2)` (binary classification result).\n",
    "        \"\"\"\n",
    "        # Pass the input through the Conformer (Generator) layers\n",
    "        x, _ = self.generator(x)\n",
    "        # Pass the input through the PredEncoder\n",
    "        y = self.pred_encoder(y)\n",
    "\n",
    "        # Concatenate Conformer output and PredEncoder output\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "\n",
    "        # Apply linear transformation for final classification\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "dis = Discriminator(\n",
    "    input_dim=height * width,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    num_heads=1,\n",
    "    ffn_dim=8,\n",
    "    num_layers=6,\n",
    "    depthwise_conv_kernel_size=3,\n",
    "    dropout=0.1,\n",
    "    use_group_norm=False,\n",
    "    convolution_first=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "test_loader = DataLoader(goDataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for idx, batch in enumerate(test_loader):\n",
    "    print(idx)\n",
    "    print(batch.shape)\n",
    "    output, input_copy = gen(batch)\n",
    "    print(output.shape)\n",
    "    output = dis(input_copy, output)\n",
    "    print(output.shape)\n",
    "    if idx == 2:\n",
    "        break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
