{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TowydQCAwnof"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMR_4AHTwnoi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiA5zXWmwnoi"
      },
      "source": [
        "# implement game logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOKVK0g7wnoj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class GoGame:\n",
        "    \"\"\"\n",
        "    Go game class.\n",
        "    This class implements the Go game logic to be used for training the neural network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, board_size=19) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the Go game with the given board size.\n",
        "        Args:\n",
        "            board_size (int): Size of the Go board (default is 19).\n",
        "        \"\"\"\n",
        "        self.board_size = board_size\n",
        "        # TODO: change the board to a 3D tensor with 2 channels (black and white stones) -- DONE\n",
        "        # TODO: store player color as an attribute, instead of passing it as an argument to the methods\n",
        "\n",
        "        self.board = torch.zeros(\n",
        "            2, board_size, board_size, dtype=torch.float32)\n",
        "\n",
        "    def place_stone(self, x, y, color) -> None:\n",
        "        \"\"\"\n",
        "        Places a stone of the specified color at the given position (x, y) on the board.\n",
        "        Args:\n",
        "            x (float): X-coordinate of the position.\n",
        "            y (float): Y-coordinate of the position.\n",
        "            color (float): Color of the stone (1 for black, -1 for white).\n",
        "        \"\"\"\n",
        "        # TODO: change the method owing to the new board representation\n",
        "        if color == 1:  # black stone\n",
        "            self.board[0][x][y] = color\n",
        "        elif color == -1:  # white stone\n",
        "            self.board[1][x][y] = color\n",
        "        self.__remove_dead_stones(x, y, color)\n",
        "\n",
        "    def __has_liberties(self, board, x, y, color, visited, dead_stones):\n",
        "        \"\"\"\n",
        "        Checks if a stone at a given position has liberties.\n",
        "\n",
        "        Args:\n",
        "            board (torch.Tensor): Current game board.\n",
        "            x (int): X-coordinate of the position.\n",
        "            y (int): Y-coordinate of the position.\n",
        "            color (int): Color of the stone (1 for black, -1 for white).\n",
        "            visited (set): Set of visited positions to avoid infinite recursion (default is None).\n",
        "            no_liberties (set): Set of positions without liberties (default is None).\n",
        "\n",
        "        Returns:\n",
        "            tuple: (bool: True if the stone has liberties, False otherwise,\n",
        "                    set: Updated no_liberties set.)\n",
        "        \"\"\"\n",
        "        # TODO: change the method owing to the new board representation -- DONE\n",
        "        # TODO: check the correctness of the method -- DONE\n",
        "\n",
        "        # If the position has been visited before, return no liberties\n",
        "        if (x, y) in visited:\n",
        "            return False\n",
        "\n",
        "        # Mark the current position as visited\n",
        "        visited.add((x, y))\n",
        "\n",
        "        # Check if the position is out of the board bounds\n",
        "        if x < 0 or x >= len(board) or y < 0 or y >= len(board[0]):\n",
        "            return False\n",
        "\n",
        "        # If the position is empty, it has liberties\n",
        "        if board[0][x][y] == 0 and board[1][x][y] == 0:\n",
        "            return True\n",
        "\n",
        "        # If the stone at the position is not of the given color, it has no liberties\n",
        "        if board[0][x][y] != 1 and board[1][x][y] != -1:\n",
        "            return False\n",
        "\n",
        "        # Recursive check for liberties in adjacent positions\n",
        "        liberties = any(\n",
        "            self.__has_liberties(board, x + dx, y + dy,\n",
        "                                 color, visited, dead_stones)\n",
        "            for dx, dy in [(1, 0), (-1, 0), (0, 1), (0, -1)]\n",
        "        )\n",
        "\n",
        "        # If the stone has no liberties, add it to the no_liberties set\n",
        "        if not liberties:\n",
        "            dead_stones.add((x, y))\n",
        "\n",
        "        return liberties\n",
        "\n",
        "    def __remove_dead_stones(self, x, y, color) -> None:\n",
        "        \"\"\"\n",
        "        Removes dead stones of the specified color from the board.\n",
        "\n",
        "        Args:\n",
        "            x (float): X-coordinate of the position.\n",
        "            y (float): Y-coordinate of the position.\n",
        "            color (float): Color of the stone (1 for black, -1 for white).\n",
        "        \"\"\"\n",
        "        # TODO: change the method owing to the new board representation\n",
        "        # TODO: check the correctness of the method\n",
        "\n",
        "        # Determine the opponent's color\n",
        "        opponent_color = -color\n",
        "\n",
        "        # Create a set to store positions of dead stones\n",
        "        dead_stones = set()\n",
        "        visited = set()\n",
        "\n",
        "        # Iterate through the neighboring positions\n",
        "        for dx, dy in [(1, 0), (-1, 0), (0, 1), (0, -1)]:\n",
        "\n",
        "            # Check if the neighboring stone has liberties\n",
        "            self.__has_liberties(\n",
        "                self.board, x + dx, y + dy, opponent_color, visited, dead_stones)\n",
        "\n",
        "        # Remove dead stones from the board\n",
        "        for x, y in dead_stones:\n",
        "            self.board[0][x][y] = 0\n",
        "            self.board[1][x][y] = 0\n",
        "\n",
        "    def get_board(self) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Returns the current game board.\n",
        "        Returns:\n",
        "            torch.Tensor: Current game board.\n",
        "        \"\"\"\n",
        "        return self.board\n",
        "\n",
        "    def reset(self) -> None:\n",
        "        \"\"\"\n",
        "        Resets the game board to the initial state.\n",
        "        \"\"\"\n",
        "        self.board = torch.zeros(\n",
        "            2, self.board_size, self.board_size, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZHKaXwiwnok"
      },
      "source": [
        "# define dataset for model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh-xZKFMwnok"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class GoDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        \"\"\"\n",
        "        Initializes the GoDataset with the given CSV file path.\n",
        "        Args:\n",
        "            path (str): Path to the CSV file containing Go game data.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.path = path\n",
        "        self.goGame = GoGame()\n",
        "        self.char2idx = {c: i for i, c in enumerate('abcdefghijklmnopqrs')}\n",
        "\n",
        "        # Load data from CSV file\n",
        "        with open(self.path, newline='') as csvfile:\n",
        "            reader = csv.reader(csvfile, delimiter=',')\n",
        "            # Read row by row\n",
        "            self.data = list(reader)  # dtype: list[str]\n",
        "            # Discard the label and player turn information, calculate the max sequence length\n",
        "            self.max_sequence_length = max([len(row) for row in self.data]) - 2\n",
        "\n",
        "    def __step(self, step):\n",
        "        \"\"\"\n",
        "        Perform a step in the game based on the given input step.\n",
        "        Args:\n",
        "            step (str): A str containing player, x-coordinate, and y-coordinate information.\n",
        "        \"\"\"\n",
        "        # TODO: change the method owing to the new board representation\n",
        "\n",
        "        current_player = -1 if step[0] == 'B' else 1\n",
        "        x = self.char2idx[step[2]]\n",
        "        y = self.char2idx[step[3]]\n",
        "        self.goGame.place_stone(x, y, current_player)\n",
        "\n",
        "    def __transform(self, data):\n",
        "        \"\"\"\n",
        "        Transform data from CSV file into a list of padded boards.\n",
        "        Args:\n",
        "            data (list): List of steps in the game.\n",
        "        Returns:\n",
        "            torch.Tensor: Transformed and padded data.\n",
        "        \"\"\"\n",
        "        # TODO: change the method owing to the new board representation\n",
        "        # TODO: make a new method for rotating the board\n",
        "        # TODO: make a new method for truncating the data\n",
        "        # TODO: modify the return value to return a tuple (previous_board, current_board)\n",
        "\n",
        "        transformed_data = []\n",
        "        for i in range(2, len(data)):\n",
        "            self.__step(data[i])\n",
        "            transformed_data.append(self.goGame.get_board().clone())\n",
        "\n",
        "        # Pad the data to the maximum sequence length with a very large negative value\n",
        "        padded_data = torch.full(\n",
        "            (self.max_sequence_length, 19, 19), -1e9, dtype=torch.float32)\n",
        "        for i in range(len(transformed_data)):\n",
        "            padded_data[i, :, :] = transformed_data[i]\n",
        "\n",
        "        return padded_data\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of samples in the dataset.\n",
        "        Returns:\n",
        "            int: Number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Get data at the given index.\n",
        "        Args:\n",
        "            idx (int): Index of the data sample.\n",
        "        Returns:\n",
        "            torch.Tensor: Processed and padded data sample.\n",
        "        \"\"\"\n",
        "        # Get data at the given index\n",
        "        row = self.data[idx]\n",
        "\n",
        "        # Transform data into a board\n",
        "        self.goGame.reset()\n",
        "        processed_data = self.__transform(row)\n",
        "        return processed_data\n",
        "\n",
        "\n",
        "goDataset = GoDataset('data/train/dan_train.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5GwxP4mwnok"
      },
      "source": [
        "# visualize game"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oap6wOd6wnol"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "\n",
        "def draw_board(board):\n",
        "    \"\"\"\n",
        "    Draws the Go board with stones based on the provided board configuration.\n",
        "    Args:\n",
        "        board (numpy.ndarray): 2D array representing the Go board (-1 for black stones, 1 for white stones, 0 for empty).\n",
        "    Returns:\n",
        "        numpy.ndarray: RGB image of the Go board with stones and grid lines.\n",
        "    \"\"\"\n",
        "    # TODO: change the method owing to the new board representation\n",
        "\n",
        "    # Create an RGB image (3 channels) with a green background\n",
        "    image = np.ones((20*20, 20*20, 3), dtype=np.uint8) * \\\n",
        "        173  # RGB value for green\n",
        "\n",
        "    # Draw lines for the board grid\n",
        "    for i in range(1, 20):\n",
        "        cv2.line(image, (i * 20, 20), (i * 20, 20*20 - 20),\n",
        "                 color=(0, 0, 0), thickness=1)\n",
        "        cv2.line(image, (20, i * 20), (20*20 - 20, i * 20),\n",
        "                 color=(0, 0, 0), thickness=1)\n",
        "\n",
        "    black = (0, 0, 0)  # RGB for black\n",
        "    white = (255, 255, 255)  # RGB for white\n",
        "    # Draw stones on the board\n",
        "    for row in range(19):\n",
        "        for col in range(19):\n",
        "            if board[row][col] == -1:  # Black stone\n",
        "                cv2.circle(image, (col * 20 + 20, row * 20 + 20),\n",
        "                           8, black, -1)  # Draw a filled circle\n",
        "            elif board[row][col] == 1:  # White stone\n",
        "                cv2.circle(image, (col * 20 + 20, row * 20 + 20),\n",
        "                           8, white, -1)  # Draw a filled circle\n",
        "\n",
        "    return image\n",
        "\n",
        "# boards = goDataset[0]\n",
        "# for i in range(10):\n",
        "#     image = draw_board(boards[i].numpy())\n",
        "#     plt.imshow(image)\n",
        "#     plt.show()\n",
        "#     time.sleep(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyvdbbgNwnol"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "\n",
        "def save_as_video(boards):\n",
        "    \"\"\"\n",
        "    Saves a sequence of Go board states as a video file.\n",
        "    Args:\n",
        "        boards (list): List of 2D numpy arrays representing Go board states.\n",
        "    \"\"\"\n",
        "    # TODO: change the method owing to the new board representation\n",
        "\n",
        "    # Define the codec and create a VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for video format (MP4)\n",
        "    # VideoWriter(filename, codec, fps, frameSize)\n",
        "    video = cv2.VideoWriter('test.mp4', fourcc, 7,\n",
        "                            (20*20, 20*20))  # VideoWriter object\n",
        "\n",
        "    # Iterate through the list of board states and save them as frames in the video\n",
        "    for board in boards:\n",
        "        image = draw_board(board)  # Convert board state to an RGB image\n",
        "        video.write(image)  # Write the image as a frame in the video\n",
        "\n",
        "    # Release the VideoWriter object, finalizing the video creation\n",
        "    video.release()\n",
        "\n",
        "\n",
        "# boards = goDataset.__getitem__(0)\n",
        "# save_as_video(boards)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTlZpEkzwnol"
      },
      "source": [
        "# PredEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2rB2SGrwnol"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class PredEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    PredNet encoder module.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): input dimension.\n",
        "        num_channels (int): number of depthwise convolution layer input channels.\n",
        "        depthwise_kernel_size (int): kernel size of depthwise convolution layer.\n",
        "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
        "        bias (bool, optional): indicates whether to add bias term to each convolution layer. (Default: ``False``)\n",
        "        use_group_norm (bool, optional): use GroupNorm rather than BatchNorm. (Default: ``False``)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        num_channels: int,\n",
        "        depthwise_kernel_size: int,\n",
        "        dropout: float = 0.0,\n",
        "        bias: bool = False,\n",
        "        use_group_norm: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if (depthwise_kernel_size - 1) % 2 != 0:\n",
        "            raise ValueError(\n",
        "                \"depthwise_kernel_size must be odd to achieve 'SAME' padding.\")\n",
        "\n",
        "        # Layer normalization for input\n",
        "        self.layer_norm = nn.LayerNorm(input_dim)\n",
        "\n",
        "        # Sequential layers: 1x1 Conv, GLU, Depthwise Conv, Normalization, Activation, 1x1 Conv, Dropout\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                input_dim,\n",
        "                2 * num_channels,\n",
        "                1,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "                bias=bias,\n",
        "            ),\n",
        "            nn.GLU(dim=1),\n",
        "            nn.Conv1d(\n",
        "                num_channels,\n",
        "                num_channels,\n",
        "                depthwise_kernel_size,\n",
        "                stride=1,\n",
        "                padding=(depthwise_kernel_size - 1) // 2,\n",
        "                groups=num_channels,\n",
        "                bias=bias,\n",
        "            ),\n",
        "            nn.GroupNorm(num_groups=1, num_channels=num_channels)\n",
        "            if use_group_norm\n",
        "            else nn.BatchNorm1d(num_channels),\n",
        "            nn.SiLU(),  # SiLU activation function (Sigmoid Linear Unit)\n",
        "            nn.Conv1d(\n",
        "                num_channels,\n",
        "                input_dim,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "                bias=bias,\n",
        "            ),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of the Conformer convolution module.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Input tensor with shape `(B, D)`.\n",
        "            B: Batch size, D: Input dimension\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with shape `(B, D)`.\n",
        "        \"\"\"\n",
        "        # input: (B, D) -> (B, 1, D)\n",
        "        x = input.unsqueeze(1)\n",
        "        x = self.layer_norm(x)\n",
        "\n",
        "        # x: (B, 1, D) -> (B, D, 1)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.sequential(x)\n",
        "\n",
        "        return x.squeeze(2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv70xZSJwnom"
      },
      "source": [
        "# conformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxKLlXr3wnom"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ConvModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Conformer convolution module.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): input dimension.\n",
        "        num_channels (int): number of depthwise convolution layer input channels.\n",
        "        depthwise_kernel_size (int): kernel size of depthwise convolution layer.\n",
        "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
        "        bias (bool, optional): indicates whether to add bias term to each convolution layer. (Default: ``False``)\n",
        "        use_group_norm (bool, optional): use GroupNorm rather than BatchNorm. (Default: ``False``)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        num_channels: int,\n",
        "        depthwise_kernel_size: int,\n",
        "        dropout: float = 0.0,\n",
        "        bias: bool = False,\n",
        "        use_group_norm: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if (depthwise_kernel_size - 1) % 2 != 0:\n",
        "            raise ValueError(\n",
        "                \"depthwise_kernel_size must be odd to achieve 'SAME' padding.\")\n",
        "\n",
        "        # Layer normalization for input\n",
        "        self.layer_norm = nn.LayerNorm(input_dim)\n",
        "\n",
        "        # Sequential layers: 1x1 Conv, GLU, Depthwise Conv, Normalization, Activation, 1x1 Conv, Dropout\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                input_dim,\n",
        "                2 * num_channels,\n",
        "                1,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "                bias=bias,\n",
        "            ),\n",
        "            nn.GLU(dim=1),\n",
        "            nn.Conv1d(\n",
        "                num_channels,\n",
        "                num_channels,\n",
        "                depthwise_kernel_size,\n",
        "                stride=1,\n",
        "                padding=(depthwise_kernel_size - 1) // 2,\n",
        "                groups=num_channels,\n",
        "                bias=bias,\n",
        "            ),\n",
        "            nn.GroupNorm(num_groups=1, num_channels=num_channels)\n",
        "            if use_group_norm\n",
        "            else nn.BatchNorm1d(num_channels),\n",
        "            nn.SiLU(),  # SiLU activation function (Sigmoid Linear Unit)\n",
        "            nn.Conv1d(\n",
        "                num_channels,\n",
        "                input_dim,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "                bias=bias,\n",
        "            ),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of the Conformer convolution module.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Input tensor with shape `(B, T, D)`.\n",
        "            B: Batch size, T: Sequence length, D: Input dimension\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with shape `(B, T, D)`.\n",
        "        \"\"\"\n",
        "        x = self.layer_norm(input)\n",
        "        # Transpose to shape `(B, D, T)` for 1D convolutions\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.sequential(x)  # Apply sequential layers\n",
        "        return x.transpose(1, 2)  # Transpose back to shape `(B, T, D)`\n",
        "\n",
        "\n",
        "class FeedForwardModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Feedforward module with Layer Normalization, Linear layers, SiLU activation, and Dropout.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Input dimension.\n",
        "        hidden_dim (int): Hidden layer dimension.\n",
        "        dropout (float, optional): Dropout probability. (Default: 0.1)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
        "        super(FeedForwardModule, self).__init__()\n",
        "        self.module = nn.Sequential(\n",
        "            nn.LayerNorm(input_dim),\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.SiLU(),  # SiLU activation function (Sigmoid Linear Unit)\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, input_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the FeedForwardModule.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape `(B, T, D)`.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with the same shape as the input tensor.\n",
        "        \"\"\"\n",
        "        return self.module(x)\n",
        "\n",
        "\n",
        "class ConformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Conformer layer that constitutes Conformer.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): input dimension.\n",
        "        ffn_dim (int): hidden layer dimension of the feedforward network.\n",
        "        num_attention_heads (int): number of attention heads.\n",
        "        depthwise_conv_kernel_size (int): kernel size of the depthwise convolution layer.\n",
        "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
        "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
        "            in the convolution module. (Default: ``False``)\n",
        "        convolution_first (bool, optional): apply the convolution module ahead of\n",
        "            the attention module. (Default: ``False``)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim,\n",
        "            ffn_dim,\n",
        "            num_attention_heads,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout=0.1,\n",
        "            use_group_norm=False,\n",
        "            convolution_first=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.ffn1 = FeedForwardModule(input_dim, ffn_dim, dropout)\n",
        "        self.ffn2 = FeedForwardModule(input_dim, ffn_dim, dropout)\n",
        "        self.conv = ConvModule(\n",
        "            input_dim,\n",
        "            input_dim,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout,\n",
        "            use_group_norm=use_group_norm,\n",
        "        )\n",
        "        self.self_attn = nn.MultiheadAttention(\n",
        "            input_dim, num_attention_heads, dropout=dropout\n",
        "        )\n",
        "        self.self_attn_dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(input_dim)\n",
        "        self.convolution_first = convolution_first\n",
        "\n",
        "    def __apply_conv(self, x):\n",
        "        \"\"\"\n",
        "        Apply the convolution module.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape `(T, B, D)`.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after applying the convolution module.\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        # Transpose to shape `(B, T, D)` for 1D convolutions\n",
        "        x = x.transpose(0, 1)\n",
        "        x = self.conv(x)\n",
        "        x = x.transpose(0, 1)  # Transpose back to shape `(T, B, D)`\n",
        "        x = x + residual\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the ConformerBlock.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape `(T, B, D)`.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with the same shape as the input tensor.\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        x = self.ffn1(x)  # First feedforward module\n",
        "        x = 0.5 * x + residual  # Residual connection and scaling\n",
        "\n",
        "        if self.convolution_first:\n",
        "            x = self.__apply_conv(x)  # Apply convolution module if specified\n",
        "\n",
        "        residual = x\n",
        "        x = self.layer_norm(x)  # Layer normalization\n",
        "        x, _ = self.self_attn(x, x, x)  # Multihead self-attention\n",
        "        x = self.self_attn_dropout(x)\n",
        "        x = x + residual  # Residual connection\n",
        "\n",
        "        if not self.convolution_first:\n",
        "            x = self.__apply_conv(x)  # Apply convolution module if specified\n",
        "\n",
        "        residual = x\n",
        "        x = self.ffn2(x)  # Second feedforward module\n",
        "        x = 0.5 * x + residual  # Residual connection and scaling\n",
        "        x = self.layer_norm(x)  # Final layer normalization\n",
        "        return x\n",
        "\n",
        "\n",
        "class Conformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        input_dim (int): input dimension.\n",
        "        num_heads (int): number of attention heads in each Conformer layer.\n",
        "        ffn_dim (int): hidden layer dimension of feedforward networks.\n",
        "        num_layers (int): number of Conformer layers to instantiate.\n",
        "        depthwise_conv_kernel_size (int): kernel size of each Conformer layer's depthwise convolution layer.\n",
        "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
        "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
        "            in the convolution module. (Default: ``False``)\n",
        "        convolution_first (bool, optional): apply the convolution module ahead of\n",
        "            the attention module. (Default: ``False``)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim,\n",
        "            num_heads,\n",
        "            ffn_dim,\n",
        "            num_layers,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout=0.1,\n",
        "            use_group_norm=False,\n",
        "            convolution_first=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Instantiate Conformer blocks\n",
        "        self.conformer_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConformerBlock(\n",
        "                    input_dim,\n",
        "                    ffn_dim,\n",
        "                    num_heads,\n",
        "                    depthwise_conv_kernel_size,\n",
        "                    dropout,\n",
        "                    use_group_norm,\n",
        "                    convolution_first,\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the Generator (Conformer model).\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input with shape `(B, T, input_dim)`.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: output with shape `(B, T, input_dim)`.\n",
        "        \"\"\"\n",
        "        batch_size, seq_length, _, _ = x.shape\n",
        "        x = x.view(batch_size, seq_length, -1)  # Flatten input tensor\n",
        "\n",
        "        x = x.transpose(0, 1)  # Transpose to shape `(T, B, input_dim)`\n",
        "\n",
        "        # Pass input through Conformer blocks\n",
        "        for layer in self.conformer_blocks:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = x.transpose(0, 1)  # Transpose back to shape `(B, T, input_dim)`\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEle7498wnom"
      },
      "source": [
        "# generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LIOABeAwnom"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    Model: Conformer\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): input dimension.\n",
        "        output_dim (int): output dimension.\n",
        "        num_heads (int): number of attention heads in each Conformer layer.\n",
        "        ffn_dim (int): hidden layer dimension of feedforward networks.\n",
        "        num_layers (int): number of Conformer layers to instantiate.\n",
        "        depthwise_conv_kernel_size (int): kernel size of each Conformer layer's depthwise convolution layer.\n",
        "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
        "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
        "            in the convolution module. (Default: ``False``)\n",
        "        convolution_first (bool, optional): apply the convolution module ahead of\n",
        "            the attention module. (Default: ``False``)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim,\n",
        "            output_dim,\n",
        "            num_heads,\n",
        "            ffn_dim,\n",
        "            num_layers,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout=0.1,\n",
        "            use_group_norm=False,\n",
        "            convolution_first=False,\n",
        "    ):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Instantiate the Conformer module\n",
        "        self.conformer = Conformer(\n",
        "            input_dim,\n",
        "            num_heads,\n",
        "            ffn_dim,\n",
        "            num_layers,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout,\n",
        "            use_group_norm,\n",
        "            convolution_first,\n",
        "        )\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the Generator (Conformer model).\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input with shape `(B, T, input_dim)`.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: output with shape `(B, output_dim)`.\n",
        "        \"\"\"\n",
        "        input_copy = torch.clone(x)\n",
        "\n",
        "        # Pass the input through the Conformer layers\n",
        "        conformer_output = self.conformer(x)\n",
        "\n",
        "        # Reshape the output for the linear layer\n",
        "        B, T, D = conformer_output.shape\n",
        "        reshaped_output = conformer_output.reshape(B, T * D)\n",
        "\n",
        "        # Apply linear transformation\n",
        "        linear_output = nn.Linear(\n",
        "            reshaped_output.shape[1], self.output_dim)(reshaped_output)\n",
        "        # Apply log softmax activation\n",
        "        output = nn.LogSoftmax(dim=1)(linear_output)\n",
        "        # nn.crossEntropyLoss() expects the output to be of shape (B, output_dim)\n",
        "\n",
        "        return output, input_copy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeMnBZnrwnom"
      },
      "source": [
        "# discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruxLkgDXwnon"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Model: Conformer, PredEncoder\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): input dimension for Conformer.\n",
        "        num_heads (int): number of attention heads in each Conformer layer.\n",
        "        ffn_dim (int): hidden layer dimension of feedforward networks in Conformer.\n",
        "        num_layers (int): number of Conformer layers to instantiate.\n",
        "        depthwise_conv_kernel_size (int): kernel size of each Conformer layer's depthwise convolution layer.\n",
        "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
        "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
        "            in the convolution module. (Default: ``False``)\n",
        "        convolution_first (bool, optional): apply the convolution module ahead of\n",
        "            the attention module. (Default: ``False``)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim,\n",
        "            num_heads,\n",
        "            ffn_dim,\n",
        "            num_layers,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout=0.1,\n",
        "            use_group_norm=False,\n",
        "            convolution_first=False,\n",
        "    ):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Instantiate the Generator (Conformer) module\n",
        "        self.generator = Generator(\n",
        "            input_dim,\n",
        "            input_dim,\n",
        "            num_heads,\n",
        "            ffn_dim,\n",
        "            num_layers,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout,\n",
        "            use_group_norm,\n",
        "            convolution_first,\n",
        "        )\n",
        "\n",
        "        # Instantiate the PredEncoder module\n",
        "        self.pred_encoder = PredEncoder(\n",
        "            input_dim=input_dim,\n",
        "            num_channels=input_dim,\n",
        "            depthwise_kernel_size=3,\n",
        "            bias=False,\n",
        "            use_group_norm=False,\n",
        "        )\n",
        "\n",
        "        # Linear layers for final classification\n",
        "        self.linear = nn.Sequential(\n",
        "            # Concatenate Conformer output and PredEncoder output\n",
        "            nn.Linear(2 * input_dim, input_dim // 2),\n",
        "            nn.BatchNorm1d(input_dim // 2),\n",
        "            nn.SiLU(),\n",
        "            # Output one-hut vector for binary classification\n",
        "            nn.Linear(input_dim // 2, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        \"\"\"\n",
        "        Forward pass of the Discriminator.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input with shape `(B, T, input_dim)` (for Conformer).\n",
        "            y (torch.Tensor): input with shape `(B, height * width)` (for PredEncoder).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: output with shape `(B, 2)` (binary classification result).\n",
        "        \"\"\"\n",
        "        # Pass the input through the Conformer (Generator) layers\n",
        "        x, _ = self.generator(x)\n",
        "        # Pass the input through the PredEncoder\n",
        "        # G(x) or ground truth y or ground truth with wrong cond\n",
        "        y = self.pred_encoder(y)\n",
        "\n",
        "        # Concatenate Conformer output and PredEncoder output\n",
        "        x = torch.cat((x, y), dim=1)\n",
        "\n",
        "        # Apply linear transformation for final classification\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqxRLt_wwnon"
      },
      "source": [
        "# models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNvX3sDawnon"
      },
      "outputs": [],
      "source": [
        "height, width = 19, 19\n",
        "\n",
        "gen = Generator(\n",
        "    input_dim=height * width,\n",
        "    output_dim=height * width,\n",
        "    num_heads=1,\n",
        "    ffn_dim=8,\n",
        "    num_layers=6,\n",
        "    depthwise_conv_kernel_size=3,\n",
        "    dropout=0.1,\n",
        "    use_group_norm=False,\n",
        "    convolution_first=False,\n",
        ")\n",
        "\n",
        "\n",
        "dis = Discriminator(\n",
        "    input_dim=height * width,\n",
        "    num_heads=1,\n",
        "    ffn_dim=8,\n",
        "    num_layers=6,\n",
        "    depthwise_conv_kernel_size=3,\n",
        "    dropout=0.1,\n",
        "    use_group_norm=False,\n",
        "    convolution_first=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUHVNGK8wnon"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5t-Rpw9cwnon"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "test_loader = DataLoader(goDataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(f'batch size: {batch_size}')\n",
        "start = time.time()\n",
        "for idx, batch in enumerate(test_loader):\n",
        "    print(f'time for {idx}th data preprocessing: {time.time() - start}')\n",
        "    print(batch.shape)\n",
        "    with torch.no_grad():\n",
        "        output, input_copy = gen(batch)\n",
        "        print(output.shape)\n",
        "        output = dis(input_copy, output)\n",
        "        print(output.shape)\n",
        "\n",
        "    start = time.time()\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
<<<<<<< HEAD
  "nbformat": 4,
  "nbformat_minor": 0
=======
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed = 11032006\n",
    "set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement game logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class GoGame:\n",
    "    \"\"\"\n",
    "    Go game class.\n",
    "    This class implements the Go game logic to be used for training the neural network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, board_size=19) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the Go game with the given board size.\n",
    "        Args:\n",
    "            board_size (int): Size of the Go board (default is 19).\n",
    "        \"\"\"\n",
    "\n",
    "        self.board_size = board_size\n",
    "        self.board = torch.zeros((2, board_size, board_size), dtype=torch.float32)\n",
    "\n",
    "    def place_stone(self, x, y, dim) -> None:\n",
    "        \"\"\"\n",
    "        Places a stone of the specified color at the given position (x, y) on the board.\n",
    "        Args:\n",
    "            x (float): X-coordinate of the position.\n",
    "            y (float): Y-coordinate of the position.\n",
    "            dim (float): Color of the stone (0 for black, 1 for white).\n",
    "        \"\"\"\n",
    "        self.board[dim][x][y] = 1\n",
    "        self.__remove_dead_stones(x, y, dim)\n",
    "\n",
    "    def __find_group_to_be_remove(self, x, y, dim) -> set:\n",
    "        \"\"\"\n",
    "        Finds a group of stones of the specified color to be removed from the board.\n",
    "        Args:\n",
    "            x (float): X-coordinate of the position.\n",
    "            y (float): Y-coordinate of the position.\n",
    "            dim (float): Color of the stone (0 for black, 1 for white).\n",
    "        Returns:\n",
    "            set: Set of positions of stones in the group.\n",
    "        \"\"\"\n",
    "        # Create a set to store positions of stones in the group\n",
    "        group = set()\n",
    "\n",
    "        # Create a set to store positions of stones to be checked\n",
    "        to_be_check = set([(x, y)])\n",
    "\n",
    "        # if the position has no stone, return an empty group\n",
    "        if self.board[dim][x][y] == 0:\n",
    "            return group\n",
    "\n",
    "        # Iterate through the positions to be checked\n",
    "        while len(to_be_check) > 0:\n",
    "            # Pop the position to be checked\n",
    "            x, y = to_be_check.pop()\n",
    "\n",
    "            # Check if the position is already in the group\n",
    "            if (x, y) in group:\n",
    "                continue\n",
    "\n",
    "            # if the position is opponent's stone, continue\n",
    "            if self.board[-dim + 1][x][y] == 1:\n",
    "                continue\n",
    "\n",
    "            # if the position is empty, it has liberty, so this group is not dead\n",
    "            if self.board[-dim + 1][x][y] == 0 and self.board[dim][x][y] == 0:\n",
    "                return set()\n",
    "\n",
    "            # Add the position to the group\n",
    "            group.add((x, y))\n",
    "\n",
    "            # Add the neighbors to the positions to be checked\n",
    "            for dx, dy in [(1, 0), (-1, 0), (0, 1), (0, -1)]:\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if nx < 0 or nx >= self.board_size or ny < 0 or ny >= self.board_size:\n",
    "                    continue\n",
    "                to_be_check.add((nx, ny))\n",
    "\n",
    "        return group\n",
    "\n",
    "    def __remove_dead_stones(self, x, y, dim) -> None:\n",
    "        \"\"\"\n",
    "        Removes dead stones of the specified color from the board.\n",
    "\n",
    "        Args:\n",
    "            x (float): X-coordinate of the position.\n",
    "            y (float): Y-coordinate of the position.\n",
    "            dim (float): Color of the stone (0 for black, 1 for white).\n",
    "        \"\"\"\n",
    "\n",
    "        # Determine the opponent's dimension\n",
    "        opponent_dim = -dim + 1\n",
    "\n",
    "        # Find groups of opponent stones to be removed\n",
    "        for dx, dy in [(1, 0), (-1, 0), (0, 1), (0, -1)]:\n",
    "            # find neighbor stones of the same color\n",
    "            nx, ny = x + dx, y + dy\n",
    "            if nx < 0 or nx >= self.board_size or ny < 0 or ny >= self.board_size:\n",
    "                continue\n",
    "            if self.board[opponent_dim][nx][ny] == 0:\n",
    "                continue\n",
    "            # Remove the group if it has no liberty\n",
    "            group = self.__find_group_to_be_remove(nx, ny, opponent_dim)\n",
    "            for gx, gy in group:\n",
    "                self.board[opponent_dim][gx][gy] = 0\n",
    "\n",
    "    def get_board(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the current game board.\n",
    "        Returns:\n",
    "            torch.Tensor: Current game board.\n",
    "        \"\"\"\n",
    "        return self.board\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"\n",
    "        Resets the game board to the initial state.\n",
    "        \"\"\"\n",
    "        self.board = torch.zeros(\n",
    "            (2, self.board_size, self.board_size), dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define dataset for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "\n",
    "\n",
    "class GoDataset(Dataset):\n",
    "    def __init__(self, path, length):\n",
    "        \"\"\"\n",
    "        Initializes the GoDataset with the given CSV file path.\n",
    "        Args:\n",
    "            path (str): Path to the CSV file containing Go game data.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.length = length\n",
    "        self.goGame = GoGame()\n",
    "        self.char2idx = {c: i for i, c in enumerate(\"abcdefghijklmnopqrs\")}\n",
    "\n",
    "        # Load data from CSV file\n",
    "        with open(self.path, newline=\"\") as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=\",\")\n",
    "            # Read row by row\n",
    "            self.data = list(reader)  # dtype: list[str]\n",
    "\n",
    "    def __rotate_point(self, x, y, n, max_val=18):\n",
    "        # Perform the rotation n times\n",
    "        for _ in range(n):\n",
    "            x, y = y, max_val - x\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __step(self, step):\n",
    "        \"\"\"\n",
    "        Perform a step in the game based on the given input step.\n",
    "        Args:\n",
    "            step (str): A str containing player, x-coordinate, and y-coordinate information.\n",
    "        \"\"\"\n",
    "        dim = 0 if step[0] == \"B\" else 1\n",
    "        x = self.char2idx[step[2]]\n",
    "        y = self.char2idx[step[3]]\n",
    "        x, y = self.__rotate_point(x, y, self.rotate_times)\n",
    "        self.goGame.place_stone(x, y, dim)\n",
    "\n",
    "    def __transform(self, data):\n",
    "        \"\"\"\n",
    "        Transform data from CSV data to boards and add other features.\n",
    "        Args:\n",
    "            data (list): List of steps in the game.\n",
    "        Returns:\n",
    "            to_model (torch.Tensor): Processed data sample.\n",
    "            label (torch.Tensor): Label for the data sample.\n",
    "        \"\"\"\n",
    "        transformed_data = []\n",
    "        random_start = np.random.randint(2, len(data) - self.length - 1)\n",
    "\n",
    "        for i in range(2, random_start + self.length):\n",
    "            self.__step(data[i])\n",
    "            if i >= random_start:\n",
    "                transformed_data.append(self.goGame.get_board().clone())\n",
    "\n",
    "        to_model = torch.stack(transformed_data)\n",
    "\n",
    "        self.goGame.reset()\n",
    "        self.__step(data[random_start + self.length])\n",
    "        label = self.goGame.get_board().clone().reshape(-1)\n",
    "\n",
    "        return to_model, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        Returns:\n",
    "            int: Number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get data at the given index.\n",
    "        Args:\n",
    "            idx (int): Index of the data sample.\n",
    "        Returns:\n",
    "            torch.Tensor: Processed and padded data sample.\n",
    "        \"\"\"\n",
    "        # Get data at the given index\n",
    "        row = self.data[idx]\n",
    "\n",
    "        # Randomly rotate times\n",
    "        self.rotate_times = np.random.randint(3)\n",
    "\n",
    "        # Transform data into a board\n",
    "        self.goGame.reset()\n",
    "        processed_data, label = self.__transform(row)\n",
    "        return processed_data, label\n",
    "\n",
    "\n",
    "# goDataset = GoDataset(\"data/train/dan_train.csv\", 5)\n",
    "# print(f\"data: {goDataset[0][0].shape}, dtype: {goDataset[0][0].dtype}\")\n",
    "# print(f\"label: {goDataset[0][1].shape}, dtype: {goDataset[0][1].dtype}\")\n",
    "# # stop execution here\n",
    "# raise Exception(\"Stop execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def draw_board(board):\n",
    "    \"\"\"\n",
    "    Draws the Go board with stones based on the provided board configuration.\n",
    "    Args:\n",
    "        board (numpy.ndarray): 2D array representing the Go board (-1 for black stones, 1 for white stones, 0 for empty).\n",
    "    Returns:\n",
    "        numpy.ndarray: RGB image of the Go board with stones and grid lines.\n",
    "    \"\"\"\n",
    "    # Create an RGB image (3 channels) with a green background\n",
    "    image = np.ones((20 * 20, 20 * 20, 3), dtype=np.uint8) * 173  # RGB value for green\n",
    "\n",
    "    # Draw lines for the board grid\n",
    "    for i in range(1, 20):\n",
    "        cv2.line(\n",
    "            image, (i * 20, 20), (i * 20, 20 * 20 - 20), color=(0, 0, 0), thickness=1\n",
    "        )\n",
    "        cv2.line(\n",
    "            image, (20, i * 20), (20 * 20 - 20, i * 20), color=(0, 0, 0), thickness=1\n",
    "        )\n",
    "\n",
    "    black = (0, 0, 0)  # RGB for black\n",
    "    white = (255, 255, 255)  # RGB for white\n",
    "    # Draw stones on the board\n",
    "    for row in range(19):\n",
    "        for col in range(19):\n",
    "            if board[0][row][col] == 1:  # Black stone\n",
    "                cv2.circle(\n",
    "                    image, (col * 20 + 20, row * 20 + 20), 8, black, -1\n",
    "                )  # Draw a filled circle\n",
    "            elif board[1][row][col] == 1:  # White stone\n",
    "                cv2.circle(\n",
    "                    image, (col * 20 + 20, row * 20 + 20), 8, white, -1\n",
    "                )  # Draw a filled circle\n",
    "\n",
    "    return image\n",
    "\n",
    "goDataset = GoDataset(\"data/train/dan_train.csv\", 5)\n",
    "for _ in range(10):\n",
    "    boards, y = goDataset.__getitem__(0)\n",
    "    for i in range(0, len(boards)):\n",
    "        image = draw_board(boards[i].numpy())\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        time.sleep(1)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "# stop execution here\n",
    "raise Exception(\"Stop execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def save_as_video(boards):\n",
    "    \"\"\"\n",
    "    Saves a sequence of Go board states as a video file.\n",
    "    Args:\n",
    "        boards (list): List of 2D numpy arrays representing Go board states.\n",
    "    \"\"\"\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for video format (MP4)\n",
    "    # VideoWriter(filename, codec, fps, frameSize)\n",
    "    video = cv2.VideoWriter('test.mp4', fourcc, 1,\n",
    "                            (20*20, 20*20))  # VideoWriter object\n",
    "\n",
    "    # Iterate through the list of board states and save them as frames in the video\n",
    "    for board in boards:\n",
    "        image = draw_board(board)  # Convert board state to an RGB image\n",
    "        video.write(image)  # Write the image as a frame in the video\n",
    "\n",
    "    # Release the VideoWriter object, finalizing the video creation\n",
    "    video.release()\n",
    "\n",
    "# boards, _ = goDataset.__getitem__(0)\n",
    "# save_as_video(boards)\n",
    "\n",
    "# # stop execution here\n",
    "# raise Exception(\"Stop execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PredEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PredEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    PredNet encoder module.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        num_channels (int): number of depthwise convolution layer input channels.\n",
    "        depthwise_kernel_size (int): kernel size of depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
    "        bias (bool, optional): indicates whether to add bias term to each convolution layer. (Default: ``False``)\n",
    "        use_group_norm (bool, optional): use GroupNorm rather than BatchNorm. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        num_channels: int,\n",
    "        depthwise_kernel_size: int,\n",
    "        dropout: float = 0.0,\n",
    "        bias: bool = False,\n",
    "        use_group_norm: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if (depthwise_kernel_size - 1) % 2 != 0:\n",
    "            raise ValueError(\n",
    "                \"depthwise_kernel_size must be odd to achieve 'SAME' padding.\")\n",
    "\n",
    "        # Sequential layers: 1x1 Conv, GLU, Depthwise Conv, Normalization, Activation, 1x1 Conv, Dropout\n",
    "        self.sequential = nn.Sequential(\n",
    "            # 1x1 Convolutional layer with GLU activation\n",
    "            nn.Conv1d(\n",
    "                input_dim,\n",
    "                2 * num_channels,\n",
    "                1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.GLU(dim=1),  # Applying GLU activation along channel dimension\n",
    "            # Depthwise Convolutional layer with specified kernel size and padding\n",
    "            nn.Conv1d(\n",
    "                num_channels,\n",
    "                num_channels,\n",
    "                depthwise_kernel_size,\n",
    "                stride=1,\n",
    "                padding=(depthwise_kernel_size - 1) // 2,\n",
    "                groups=num_channels,  # Depthwise convolution with groups=num_channels\n",
    "                bias=bias,\n",
    "            ),\n",
    "            # Normalization using GroupNorm or BatchNorm\n",
    "            nn.GroupNorm(num_groups=1, num_channels=num_channels)\n",
    "            if use_group_norm\n",
    "            else nn.BatchNorm1d(num_channels),\n",
    "            nn.SiLU(),  # Applying SiLU activation function\n",
    "            # 1x1 Convolutional layer to map back to the original input dimension\n",
    "            nn.Conv1d(\n",
    "                num_channels,\n",
    "                input_dim,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            # Dropout layer with specified dropout probability\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the PredNet encoder module.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor with shape `(B, D)`.\n",
    "            B: Batch size, D: Input dimension\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with shape `(B, D)`.\n",
    "        \"\"\"\n",
    "        # input: (B, D) -> (B, D, 1)\n",
    "        x = input.unsqueeze(-1)\n",
    "\n",
    "        x = self.sequential(x)  # Applying sequential layers\n",
    "\n",
    "        # Removing singleton dimension and returning the output tensor\n",
    "        return x.squeeze(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Conformer convolution module.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        num_channels (int): number of depthwise convolution layer input channels.\n",
    "        depthwise_kernel_size (int): kernel size of depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
    "        bias (bool, optional): indicates whether to add bias term to each convolution layer. (Default: ``False``)\n",
    "        use_group_norm (bool, optional): use GroupNorm rather than BatchNorm. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        num_channels: int,\n",
    "        depthwise_kernel_size: int,\n",
    "        dropout: float = 0.0,\n",
    "        bias: bool = False,\n",
    "        use_group_norm: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if (depthwise_kernel_size - 1) % 2 != 0:\n",
    "            raise ValueError(\n",
    "                \"depthwise_kernel_size must be odd to achieve 'SAME' padding.\"\n",
    "            )\n",
    "\n",
    "        # Layer normalization for input\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "\n",
    "        # Sequential layers: 1x1 Conv, GLU, Depthwise Conv, Normalization, Activation, 1x1 Conv, Dropout\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                input_dim,\n",
    "                2 * num_channels,\n",
    "                1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.GLU(dim=1),\n",
    "            nn.Conv1d(\n",
    "                num_channels,\n",
    "                num_channels,\n",
    "                depthwise_kernel_size,\n",
    "                stride=1,\n",
    "                padding=(depthwise_kernel_size - 1) // 2,\n",
    "                groups=num_channels,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.GroupNorm(num_groups=1, num_channels=num_channels)\n",
    "            if use_group_norm\n",
    "            else nn.BatchNorm1d(num_channels),\n",
    "            nn.SiLU(),  # SiLU activation function (Sigmoid Linear Unit)\n",
    "            nn.Conv1d(\n",
    "                num_channels,\n",
    "                input_dim,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Conformer convolution module.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor with shape `(B, T, D)`.\n",
    "            B: Batch size, T: Sequence length, D: Input dimension\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with shape `(B, T, D)`.\n",
    "        \"\"\"\n",
    "        x = self.layer_norm(input)\n",
    "        # Transpose to shape `(B, D, T)` for 1D convolutions\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.sequential(x)  # Apply sequential layers\n",
    "        return x.transpose(1, 2)  # Transpose back to shape `(B, T, D)`\n",
    "\n",
    "\n",
    "class FeedForwardModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Feedforward module with Layer Normalization, Linear layers, SiLU activation, and Dropout.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Input dimension.\n",
    "        hidden_dim (int): Hidden layer dimension.\n",
    "        dropout (float, optional): Dropout probability. (Default: 0.1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
    "        super(FeedForwardModule, self).__init__()\n",
    "        self.module = nn.Sequential(\n",
    "            nn.LayerNorm(input_dim),\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),  # SiLU activation function (Sigmoid Linear Unit)\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the FeedForwardModule.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape `(B, T, D)`.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with the same shape as the input tensor.\n",
    "        \"\"\"\n",
    "        return self.module(x)\n",
    "\n",
    "\n",
    "class ConformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Conformer layer that constitutes Conformer.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        ffn_dim (int): hidden layer dimension of the feedforward network.\n",
    "        num_attention_heads (int): number of attention heads.\n",
    "        depthwise_conv_kernel_size (int): kernel size of the depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
    "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
    "            in the convolution module. (Default: ``False``)\n",
    "        convolution_first (bool, optional): apply the convolution module ahead of\n",
    "            the attention module. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        ffn_dim,\n",
    "        num_attention_heads,\n",
    "        depthwise_conv_kernel_size,\n",
    "        dropout=0.1,\n",
    "        use_group_norm=False,\n",
    "        convolution_first=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ffn1 = FeedForwardModule(input_dim, ffn_dim, dropout)\n",
    "        self.ffn2 = FeedForwardModule(input_dim, ffn_dim, dropout)\n",
    "        self.conv = ConvModule(\n",
    "            input_dim,\n",
    "            input_dim,\n",
    "            depthwise_conv_kernel_size,\n",
    "            dropout,\n",
    "            use_group_norm=use_group_norm,\n",
    "        )\n",
    "        self.self_attn = nn.MultiheadAttention(\n",
    "            input_dim, num_attention_heads, dropout=dropout\n",
    "        )\n",
    "        self.self_attn_dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "        self.convolution_first = convolution_first\n",
    "\n",
    "    def __apply_conv(self, x):\n",
    "        \"\"\"\n",
    "        Apply the convolution module.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape `(T, B, D)`.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after applying the convolution module.\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        # Transpose to shape `(B, T, D)` for 1D convolutions\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(0, 1)  # Transpose back to shape `(T, B, D)`\n",
    "        x = x + residual\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the ConformerBlock.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape `(T, B, D)`.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with the same shape as the input tensor.\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        x = self.ffn1(x)  # First feedforward module\n",
    "        x = 0.5 * x + residual  # Residual connection and scaling\n",
    "\n",
    "        if self.convolution_first:\n",
    "            x = self.__apply_conv(x)  # Apply convolution module if specified\n",
    "\n",
    "        residual = x\n",
    "        x = self.layer_norm(x)  # Layer normalization\n",
    "        x, _ = self.self_attn(x, x, x)  # Multihead self-attention\n",
    "        x = self.self_attn_dropout(x)\n",
    "        x = x + residual  # Residual connection\n",
    "\n",
    "        if not self.convolution_first:\n",
    "            x = self.__apply_conv(x)  # Apply convolution module if specified\n",
    "\n",
    "        residual = x\n",
    "        x = self.ffn2(x)  # Second feedforward module\n",
    "        x = 0.5 * x + residual  # Residual connection and scaling\n",
    "        x = self.layer_norm(x)  # Final layer normalization\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_dim (int): input dimension.\n",
    "        num_heads (int): number of attention heads in each Conformer layer.\n",
    "        ffn_dim (int): hidden layer dimension of feedforward networks.\n",
    "        num_layers (int): number of Conformer layers to instantiate.\n",
    "        depthwise_conv_kernel_size (int): kernel size of each Conformer layer's depthwise convolution layer.\n",
    "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
    "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
    "            in the convolution module. (Default: ``False``)\n",
    "        convolution_first (bool, optional): apply the convolution module ahead of\n",
    "            the attention module. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        num_heads,\n",
    "        ffn_dim,\n",
    "        num_layers,\n",
    "        depthwise_conv_kernel_size,\n",
    "        dropout=0.1,\n",
    "        use_group_norm=False,\n",
    "        convolution_first=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Instantiate Conformer blocks\n",
    "        self.conformer_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ConformerBlock(\n",
    "                    input_dim,\n",
    "                    ffn_dim,\n",
    "                    num_heads,\n",
    "                    depthwise_conv_kernel_size,\n",
    "                    dropout,\n",
    "                    use_group_norm,\n",
    "                    convolution_first,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward pass of the Generator (Conformer model).\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): input with shape `(B, T, input_dim)`.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: output with shape `(B, T, input_dim)`.\n",
    "        \"\"\"\n",
    "        batch_size, seq_length, _, _, _ = x.shape\n",
    "        x = x.view(batch_size, seq_length, -1)  # Flatten input tensor\n",
    "\n",
    "        x = x.transpose(0, 1)  # Transpose to shape `(T, B, input_dim)`\n",
    "\n",
    "        # Pass input through Conformer blocks\n",
    "        for layer in self.conformer_blocks:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = x.transpose(0, 1)  # Transpose back to shape `(B, T, input_dim)`\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator model using Conformer architecture.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Input dimension.\n",
    "        num_heads (int): Number of attention heads in each Conformer layer.\n",
    "        ffn_dim (int): Hidden layer dimension of feedforward networks in Conformer layers.\n",
    "        num_layers (int): Number of Conformer layers.\n",
    "        depthwise_conv_kernel_size (int): Kernel size of depthwise convolution in Conformer layers.\n",
    "        dropout (float, optional): Dropout probability. (Default: 0.1)\n",
    "        use_group_norm (bool, optional): Use GroupNorm instead of BatchNorm1d in Conformer layers. (Default: False)\n",
    "        convolution_first (bool, optional): Apply convolution module ahead of attention module. (Default: False)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        num_heads,\n",
    "        ffn_dim,\n",
    "        num_layers,\n",
    "        depthwise_conv_kernel_size,\n",
    "        dropout=0.1,\n",
    "        use_group_norm=False,\n",
    "        convolution_first=False,\n",
    "    ):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Instantiate the Conformer module\n",
    "        self.conformer = Conformer(\n",
    "            input_dim,\n",
    "            num_heads,\n",
    "            ffn_dim,\n",
    "            num_layers,\n",
    "            depthwise_conv_kernel_size,\n",
    "            dropout,\n",
    "            use_group_norm,\n",
    "            convolution_first,\n",
    "        )\n",
    "\n",
    "        # Output layer: Linear + Softmax\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            # TODO: try different activation functions\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward pass of the Generator (Conformer model).\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape `(B, T, input_dim)`.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with shape `(B, output_dim)`.\n",
    "        \"\"\"\n",
    "        # Pass the input through the Conformer layers\n",
    "        conformer_output = self.conformer(x)\n",
    "\n",
    "        # truncate the output to the last time step\n",
    "        output = conformer_output[:, -1, :]\n",
    "\n",
    "        # Pass the output through the linear layer\n",
    "        output = self.output_layer(output)\n",
    "\n",
    "        return output, x  # Return the original input tensor without cloning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator model using Conformer and PredEncoder architectures.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Input dimension for Conformer and PredEncoder.\n",
    "        num_heads (int): Number of attention heads in each Conformer layer.\n",
    "        ffn_dim (int): Hidden layer dimension of feedforward networks in Conformer.\n",
    "        num_layers (int): Number of Conformer layers.\n",
    "        depthwise_conv_kernel_size (int): Kernel size of depthwise convolution in Conformer.\n",
    "        dropout (float, optional): Dropout probability. (Default: 0.1)\n",
    "        use_group_norm (bool, optional): Use GroupNorm instead of BatchNorm1d in Conformer layers. (Default: False)\n",
    "        convolution_first (bool, optional): Apply convolution module ahead of attention module. (Default: False)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        num_heads,\n",
    "        ffn_dim,\n",
    "        num_layers,\n",
    "        depthwise_conv_kernel_size,\n",
    "        dropout=0.1,\n",
    "        use_group_norm=False,\n",
    "        convolution_first=False,\n",
    "    ):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # Instantiate the Generator (Conformer) module\n",
    "        self.generator = Generator(\n",
    "            input_dim,\n",
    "            num_heads,\n",
    "            ffn_dim,\n",
    "            num_layers,\n",
    "            depthwise_conv_kernel_size,\n",
    "            dropout,\n",
    "            use_group_norm,\n",
    "            convolution_first,\n",
    "        )\n",
    "\n",
    "        # Instantiate the PredEncoder module\n",
    "        self.pred_encoder = PredEncoder(\n",
    "            input_dim=input_dim,\n",
    "            num_channels=input_dim,\n",
    "            depthwise_kernel_size=3,\n",
    "            bias=False,\n",
    "            use_group_norm=False,\n",
    "        )\n",
    "\n",
    "        # TODO: try different activation functions\n",
    "        # Linear layers for final classification\n",
    "        self.linear = nn.Sequential(\n",
    "            # Concatenate Conformer output and PredEncoder output\n",
    "            # Output dimension reduced by half\n",
    "            nn.Linear(2 * input_dim, input_dim // 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(input_dim // 4, input_dim // 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # Output one-hot vector for binary classification (2 classes)\n",
    "            nn.Linear(input_dim // 16, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Forward pass of the Discriminator.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape `(B, T, input_dim)` (for Conformer).\n",
    "            y (torch.Tensor): Input tensor with shape `(B, height * width)` (for PredEncoder).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with shape `(B, 2)` (binary classification result).\n",
    "        \"\"\"\n",
    "        # Pass the input through the Conformer (Generator) layers and get the input copy\n",
    "        generator_output, input_copy = self.generator(x)\n",
    "\n",
    "        # Pass the input through the PredEncoder\n",
    "        pred_encoder_output = self.pred_encoder(y)\n",
    "\n",
    "        # Concatenate Conformer output, PredEncoder output, and the original input tensor\n",
    "        concatenated_input = torch.cat(\n",
    "            (generator_output, pred_encoder_output, x), dim=1\n",
    "        )\n",
    "\n",
    "        # Apply linear transformation for final classification\n",
    "        output = self.linear(concatenated_input)\n",
    "\n",
    "        return output, input_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: dict,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        load_model: bool = False,\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "        if load_model:\n",
    "            self.gen = torch.load(config[\"gen_path\"])\n",
    "            self.dis = torch.load(config[\"dis_path\"])\n",
    "        else:\n",
    "            self.gen = Generator(\n",
    "                input_dim=config[\"input_dim\"],\n",
    "                num_heads=config[\"num_heads\"],\n",
    "                ffn_dim=config[\"ffn_dim\"],\n",
    "                num_layers=config[\"num_layers\"],\n",
    "                depthwise_conv_kernel_size=config[\"depthwise_conv_kernel_size\"],\n",
    "                dropout=config[\"dropout\"],\n",
    "                use_group_norm=config[\"use_group_norm\"],\n",
    "                convolution_first=config[\"convolution_first\"],\n",
    "            )\n",
    "            self.dis = Discriminator(\n",
    "                input_dim=config[\"input_dim\"],\n",
    "                num_heads=config[\"num_heads\"],\n",
    "                ffn_dim=config[\"ffn_dim\"],\n",
    "                num_layers=config[\"num_layers\"],\n",
    "                depthwise_conv_kernel_size=config[\"depthwise_conv_kernel_size\"],\n",
    "                dropout=config[\"dropout\"],\n",
    "                use_group_norm=config[\"use_group_norm\"],\n",
    "                convolution_first=config[\"convolution_first\"],\n",
    "            )\n",
    "        self.gen.to(self.config[\"device\"])\n",
    "        self.dis.to(self.config[\"device\"])\n",
    "\n",
    "        self.G_optimizer = torch.optim.Adam(self.gen.parameters(), lr=config[\"lr\"])\n",
    "        self.D_optimizer = torch.optim.Adam(self.dis.parameters(), lr=config[\"lr\"])\n",
    "        self.G_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.G_optimizer)\n",
    "        self.D_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.D_optimizer)\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "        self.clip_value = config[\"clip_value\"]\n",
    "\n",
    "        self.early_count = 0\n",
    "        self.best_val_loss = float(\"inf\")\n",
    "\n",
    "    def normal_evaluate_G(self, G_val_losses: list):\n",
    "        self.gen.eval()\n",
    "        for i, (x, y) in enumerate(tqdm(self.val_loader)):\n",
    "            x = x.to(self.config[\"device\"])\n",
    "            y = y.to(self.config[\"device\"])\n",
    "            output, _ = self.gen(x)\n",
    "            loss = self.criterion(output, y)\n",
    "            G_val_losses.append(loss.item())\n",
    "\n",
    "    def evaluate_G(self, G_val_losses: list, G_accs: list):\n",
    "        print(f\"Evaluating generator:\")\n",
    "\n",
    "        # Set the generator and discriminator in evaluation mode\n",
    "        self.gen.eval()\n",
    "        self.dis.eval()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        # Iterate through the validation loader\n",
    "        for i, (x, y) in enumerate(tqdm(self.val_loader)):\n",
    "            x = x.to(self.config[\"device\"])\n",
    "            y = y.to(self.config[\"device\"])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Generate fake data and conditioning information from the generator\n",
    "                output, condition = self.gen(x)\n",
    "\n",
    "                # Pass fake data and conditioning information through the discriminator\n",
    "                fake_pred, _ = self.dis(condition, output)\n",
    "\n",
    "            # Determine the predicted classes for fake and real samples\n",
    "            fake_indices = torch.argmax(fake_pred, dim=1)\n",
    "            real_indices = torch.argmax(y, dim=1)\n",
    "\n",
    "            # Count correct predictions\n",
    "            correct = torch.sum(fake_indices == real_indices)\n",
    "            total_correct += correct\n",
    "\n",
    "            # Compute generator loss for both the image output and the discriminator predictions\n",
    "            loss = self.criterion(output, y) + -torch.mean(fake_pred)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        self.G_scheduler.step(total_loss)\n",
    "\n",
    "        # Calculate and store the average generator validation loss\n",
    "        average_loss = total_loss / len(self.val_loader)\n",
    "        G_val_losses.append(average_loss)\n",
    "\n",
    "        # Calculate and store the validation accuracy\n",
    "        accuracy = total_correct / len(self.val_loader.dataset)\n",
    "        G_accs.append(accuracy)\n",
    "        print(f\"G Validation accuracy: {accuracy}\")\n",
    "\n",
    "        if average_loss < self.best_val_loss:\n",
    "            self.best_val_loss = average_loss\n",
    "            torch.save(self.gen, self.config[\"gen_path\"])\n",
    "            torch.save(self.dis, self.config[\"dis_path\"])\n",
    "            self.early_count = 0\n",
    "        else:\n",
    "            self.early_count += 1\n",
    "\n",
    "    def evaluate_D(self, D_val_losses: list, D_accs: list):\n",
    "        print(f\"Evaluating discriminator:\")\n",
    "\n",
    "        # Set the generator and discriminator in evaluation mode\n",
    "        self.gen.eval()\n",
    "        self.dis.eval()\n",
    "\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_fake_loss = 0\n",
    "        total_real_loss = 0\n",
    "\n",
    "        # Iterate through the validation loader\n",
    "        for i, (x, y) in enumerate(tqdm(self.val_loader)):\n",
    "            x = x.to(self.config[\"device\"])\n",
    "            y = y.to(self.config[\"device\"])\n",
    "\n",
    "            # Generate fake data and conditioning information from the generator\n",
    "            output, condition = self.gen(x)\n",
    "            with torch.no_grad():\n",
    "                # Pass fake data and conditioning information through the discriminator\n",
    "                fake_pred, condition = self.dis(condition, output)\n",
    "                real_pred, _ = self.dis(condition, y)\n",
    "\n",
    "            total_correct += torch.sum(fake_pred < 0.5) + torch.sum(real_pred > 0.5)\n",
    "\n",
    "            total_loss += -torch.mean(real_pred) + torch.mean(fake_pred)\n",
    "            total_fake_loss += torch.mean(fake_pred)\n",
    "            total_real_loss += -torch.mean(real_pred)\n",
    "\n",
    "        self.D_scheduler.step(total_loss)\n",
    "\n",
    "        # Calculate and store the average discriminator validation loss\n",
    "        average_loss = total_loss / len(self.val_loader)\n",
    "        D_val_losses.append(average_loss.item())\n",
    "        print(f\"Discriminator loss: {average_loss}\")\n",
    "        print(f\"Fake loss: {total_fake_loss / len(self.val_loader)}\")\n",
    "        print(f\"Real loss: {total_real_loss / len(self.val_loader)}\")\n",
    "\n",
    "        # Calculate and store the validation accuracy\n",
    "        accuracy = total_correct / len(self.val_loader.dataset) / 2\n",
    "        D_accs.append(accuracy.item())\n",
    "        print(f\"D Validation accuracy: {accuracy}\")\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    def normal_train_G(self, G_losses: list):\n",
    "        self.gen.train()\n",
    "        total_loss = 0\n",
    "        start = time.time()\n",
    "        for i, (x, y) in enumerate(tqdm(self.train_loader)):\n",
    "            data_time = time.time() - start\n",
    "            print(f\"Data time: {data_time}\")\n",
    "            self.G_optimizer.zero_grad()\n",
    "            x = x.to(self.config[\"device\"])\n",
    "            y = y.to(self.config[\"device\"])\n",
    "            output, _ = self.gen(x)\n",
    "            loss = self.criterion(output, y)\n",
    "            loss.backward()\n",
    "            self.G_optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            start = time.time()\n",
    "\n",
    "        G_losses.append(total_loss / len(self.train_loader))\n",
    "        print(f\"Generator loss: {total_loss / len(self.train_loader)}\")\n",
    "\n",
    "    def train_G(self, x, y):\n",
    "        x = x.to(self.config[\"device\"])\n",
    "        y = y.to(self.config[\"device\"])\n",
    "\n",
    "        # Generate fake data and conditioning information from the generator\n",
    "        fake_output, condition = self.gen(x)\n",
    "\n",
    "        # Pass fake data and conditioning information through the discriminator\n",
    "        fake_pred, _ = self.dis(condition, fake_output)\n",
    "\n",
    "        # Compute discriminator loss and normal loss using binary cross-entropy loss\n",
    "        D_loss = -torch.mean(fake_pred)\n",
    "        normal_loss = self.criterion(fake_output, y)\n",
    "\n",
    "        # Total loss for the generator: discriminator loss + normal loss\n",
    "        loss = D_loss + normal_loss\n",
    "\n",
    "        # Backpropagation and optimization step\n",
    "        self.G_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.gen.parameters(), max_norm=self.clip_value)\n",
    "        self.G_optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def cal_gradient_penalty(self, real, fake, condition, lambda_gp=10):\n",
    "        batch_size = real.size(0)\n",
    "        alpha = torch.rand((batch_size, 1), dtype=real.dtype, device=real.device)\n",
    "\n",
    "        # Interpolate between real and fake samples based on alpha\n",
    "        interpolates = alpha * real + (1 - alpha) * fake\n",
    "        interpolates = torch.autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "        # Pass the interpolated samples through the discriminator\n",
    "        disc_interpolates, _ = self.dis(condition, interpolates)\n",
    "\n",
    "        # Compute gradients of the interpolated samples with respect to inputs\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=disc_interpolates,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=torch.ones_like(disc_interpolates),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "\n",
    "        # Flatten and calculate the norm of the gradients for each sample in the batch\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "        gradient_norm = gradients.norm(2, dim=1)\n",
    "\n",
    "        # Calculate gradient penalty based on the Lipschitz constraint formula\n",
    "        gradient_penalty = ((gradient_norm - 1) ** 2).mean()\n",
    "\n",
    "        # Scale the gradient penalty by lambda_gp and add it to the loss\n",
    "        return lambda_gp * gradient_penalty\n",
    "\n",
    "    def train_D(self, x, y):\n",
    "        # Prevent original inputs from being changed\n",
    "        x_copy = x.clone()\n",
    "        y_copy = y.clone()\n",
    "\n",
    "        # Move real data and labels to the specified device\n",
    "        x = x.to(self.config[\"device\"])\n",
    "        y = y.to(self.config[\"device\"])\n",
    "\n",
    "        # Clone real data for the gradient penalty calculation\n",
    "        real_output = torch.clone(y)\n",
    "\n",
    "        # Generate fake data and conditioning information from the generator\n",
    "        fake_output, condition = self.gen(x)\n",
    "\n",
    "        # Pass fake data and conditioning information through the discriminator\n",
    "        fake_pred, condition = self.dis(condition, torch.clone(fake_output))\n",
    "        real_pred, condition = self.dis(condition, torch.clone(y))\n",
    "\n",
    "        # Calculate the gradient penalty\n",
    "        gradient_penalty = self.cal_gradient_penalty(\n",
    "            real_output, fake_output, condition\n",
    "        )\n",
    "\n",
    "        # Calculate the total loss: -real + fake + gradient penalty\n",
    "        loss = -torch.mean(real_pred) + torch.mean(fake_pred) + gradient_penalty\n",
    "\n",
    "        # Backpropagation and optimization step\n",
    "        self.D_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.dis.parameters(), max_norm=self.clip_value)\n",
    "        self.D_optimizer.step()\n",
    "\n",
    "        # Restore original inputs\n",
    "        x = x_copy\n",
    "        y = y_copy\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def train(self):\n",
    "        G_losses = []\n",
    "        G_val_losses = []\n",
    "        G_accs = []\n",
    "        D_losses = []\n",
    "        D_val_losses = []\n",
    "        D_accs = []\n",
    "\n",
    "        D_acc = 0\n",
    "        for epoch in range(self.config[\"epochs\"]):\n",
    "            D_total_loss = 0\n",
    "            G_total_loss = 0\n",
    "            print(f'Epoch {epoch+1}/{self.config[\"epochs\"]}')\n",
    "            for i, (x, y) in enumerate(tqdm(self.train_loader)):\n",
    "                if D_acc < 0.8:\n",
    "                    D_loss = self.train_D(x, y)\n",
    "                    D_total_loss += D_loss\n",
    "\n",
    "                G_loss = self.train_G(x, y)\n",
    "\n",
    "                G_total_loss += G_loss\n",
    "\n",
    "            print(f\"Discriminator loss: {D_total_loss / len(self.train_loader)}\")\n",
    "            D_losses.append(D_total_loss / len(self.train_loader))\n",
    "            print(f\"Generator loss: {G_total_loss / len(self.train_loader)}\")\n",
    "            G_losses.append(G_total_loss / len(self.train_loader))\n",
    "\n",
    "            D_acc = self.evaluate_D(D_val_losses, D_accs)\n",
    "            self.evaluate_G(G_val_losses, G_accs)\n",
    "\n",
    "            if self.early_count >= self.config[\"early_stop\"]:\n",
    "                break\n",
    "\n",
    "        return {\n",
    "            \"G_losses\": G_losses,\n",
    "            \"G_val_losses\": G_val_losses,\n",
    "            \"G_accs\": G_accs,\n",
    "            \"D_losses\": D_losses,\n",
    "            \"D_val_losses\": D_val_losses,\n",
    "            \"D_accs\": D_accs,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameter finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# domain = {\n",
    "#     \"input_dim\": [2 * 19 * 19],\n",
    "#     \"num_heads\": [1, 2],\n",
    "#     \"ffn_dim\": [64, 128, 256, 512, 1024],\n",
    "#     \"num_layers\": [2, 4, 8],\n",
    "#     \"depthwise_conv_kernel_size\": [3, 5, 7],\n",
    "#     \"dropout\": [0, 0.1, 0.2, 0.3, 0.4],\n",
    "#     \"use_group_norm\": [True, False],\n",
    "#     \"convolution_first\": [True, False],\n",
    "#     \"lr\": [0.0001, 0.001, 0.01],\n",
    "#     \"gen_path\": [\"data/models/gen.pth\"],\n",
    "#     \"dis_path\": [\"data/models/dis.pth\"],\n",
    "#     \"device\": [torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")],\n",
    "#     \"batch_size\": [512],\n",
    "#     \"clip_value\": [1],\n",
    "#     \"data_len\": [4, 8, 16, 32],\n",
    "#     \"epochs\": [100],\n",
    "#     \"early_stop\": [5],\n",
    "# }\n",
    "\n",
    "# for test\n",
    "domain = {\n",
    "    \"input_dim\": [2 * 19 * 19],\n",
    "    \"num_heads\": [1],\n",
    "    \"ffn_dim\": [64],\n",
    "    \"num_layers\": [2],\n",
    "    \"depthwise_conv_kernel_size\": [3],\n",
    "    \"dropout\": [0],\n",
    "    \"use_group_norm\": [True],\n",
    "    \"convolution_first\": [True],\n",
    "    \"lr\": [0.0001],\n",
    "    \"gen_path\": [\"data/models/gen.pth\"],\n",
    "    \"dis_path\": [\"data/models/dis.pth\"],\n",
    "    \"device\": [torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")],\n",
    "    \"batch_size\": [512],\n",
    "    \"clip_value\": [1],\n",
    "    \"data_len\": [4],\n",
    "    \"epochs\": [100],\n",
    "    \"early_stop\": [5],\n",
    "}\n",
    "\n",
    "# print domain count\n",
    "count = 1\n",
    "for key, value in domain.items():\n",
    "    count *= len(value)\n",
    "print(f\"Total combinations: {count}\")\n",
    "\n",
    "\n",
    "class ParmFinder:\n",
    "    def __init__(self, domain: dict) -> None:\n",
    "        # Initialize parameters and data structures\n",
    "        self.best_ratio = float(\"inf\")\n",
    "        self.best_params = None\n",
    "        self.G_parms = []\n",
    "        self.G_train_losses = []\n",
    "        self.G_ratios = []\n",
    "        self.D_parms = []\n",
    "        self.domain = domain\n",
    "        self.max_iter = 50\n",
    "        self.max_epoch = 5\n",
    "        self.G_history_path = \"data/G_history.csv\"\n",
    "\n",
    "    def __random_sample(self):\n",
    "        # Randomly sample parameters from the given domain\n",
    "        params = {}\n",
    "        for key, value in self.domain.items():\n",
    "            params[key] = np.random.choice(value)\n",
    "\n",
    "        print(f\"Current params: {params}\")\n",
    "\n",
    "        goDataset = GoDataset(\"data/train/dan_train.csv\", params[\"data_len\"])\n",
    "        train_len = int(0.8 * len(goDataset))\n",
    "        val_len = len(goDataset) - train_len\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "            goDataset, [train_len, val_len]\n",
    "        )\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset, batch_size=int(params[\"batch_size\"]), shuffle=True, pin_memory=True\n",
    "        )\n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset, batch_size=int(params[\"batch_size\"]), shuffle=False, pin_memory=True\n",
    "        )\n",
    "\n",
    "        return params\n",
    "\n",
    "    def __save_G(self):\n",
    "        # Save G_parms, G_train_losses, and G_ratios to a CSV file and best G model\n",
    "        header = list(self.domain.keys()) + [\"train_loss\", \"loss_ratio\"]\n",
    "        df = pd.DataFrame(self.G_parms, columns=header)\n",
    "        df[\"train_loss\"] = self.G_train_losses\n",
    "        df[\"loss_ratio\"] = self.G_ratios\n",
    "        df.sort_values(by=\"loss_ratio\", ascending=False, inplace=True)\n",
    "        df.to_csv(self.G_history_path, index=False)\n",
    "\n",
    "    def __evaluate_G(self, trainer: Trainer):\n",
    "        # Evaluate generator performance over multiple epochs\n",
    "        train_loss = 0\n",
    "        loss_ratio = 0\n",
    "        for epoch in range(self.max_epoch):\n",
    "            G_losses = []\n",
    "            G_val_losses = []\n",
    "            trainer.normal_train_G(G_losses)\n",
    "            trainer.normal_evaluate_G(G_val_losses)\n",
    "\n",
    "            train_loss = np.mean(G_losses)\n",
    "            val_loss = np.mean(G_val_losses)\n",
    "            loss_ratio = train_loss / val_loss\n",
    "\n",
    "            if loss_ratio < self.best_ratio:\n",
    "                self.best_ratio = loss_ratio\n",
    "                self.best_params = trainer.config\n",
    "                self.best_G = trainer.gen\n",
    "                self.best_D = trainer.dis\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{self.max_epoch}: Train Loss: {train_loss}, Val Loss: {val_loss}, Loss Ratio: {loss_ratio}\"\n",
    "            )\n",
    "\n",
    "        self.G_parms.append(trainer.config)\n",
    "        self.G_train_losses.append(train_loss)\n",
    "        self.G_ratios.append(loss_ratio)\n",
    "        self.__save_G()\n",
    "\n",
    "    def find(self):\n",
    "        # Iterate for a maximum number of iterations\n",
    "        for _ in range(self.max_iter):\n",
    "            params = self.__random_sample()\n",
    "            trainer = Trainer(params, self.train_loader, self.val_loader)\n",
    "            self.__evaluate_G(trainer)\n",
    "\n",
    "        return self.best_params, self.train_loader, self.val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parmFinder = ParmFinder(domain)\n",
    "parms, train_loader, val_loader = parmFinder.find()\n",
    "print(f\"Best params: {parms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(parms, train_loader, val_loader)\n",
    "statistic = trainer.train()\n",
    "\n",
    "print(statistic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
>>>>>>> 48a6c17cdfa1949e4d9b915dfc437a75e0644e1d
}
