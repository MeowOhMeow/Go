{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "F42WV3Ukt6EV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Nov  6 18:02:03 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 545.92                 Driver Version: 545.92       CUDA Version: 12.3     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3060 ...  WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   59C    P5              27W /  95W |    266MiB /  6144MiB |     10%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A       316    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
            "|    0   N/A  N/A      3280    C+G   ...al\\Discord\\app-1.0.9021\\Discord.exe    N/A      |\n",
            "|    0   N/A  N/A      4272    C+G   ...US\\ArmouryDevice\\asus_framework.exe    N/A      |\n",
            "|    0   N/A  N/A     12092    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     12856    C+G   ...81.0_x64__8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
            "|    0   N/A  N/A     13568    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     15736    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     16604    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     23256    C+G   ...gin\\LineCall\\1.0.0.696\\LineCall.exe    N/A      |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nMsF5QCKt6EX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci3GJJ1ft6EX"
      },
      "source": [
        "# implement game logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cmCt-mbFt6EY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class GoGame:\n",
        "    \"\"\"\n",
        "    Go game class.\n",
        "    This class implements the Go game logic to be used for training the neural network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, board_size=19) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the Go game with the given board size.\n",
        "        Args:\n",
        "            board_size (int): Size of the Go board (default is 19).\n",
        "        \"\"\"\n",
        "        self.board_size = board_size\n",
        "        # TODO: change the board to a 3D tensor with 2 channels (black and white stones) -- DONE\n",
        "        # TODO: store player color as an attribute, instead of passing it as an argument to the methods\n",
        "\n",
        "        self.board = torch.zeros(2, board_size, board_size, dtype=torch.float32)\n",
        "\n",
        "    def place_stone(self, x, y, color) -> None:\n",
        "        \"\"\"\n",
        "        Places a stone of the specified color at the given position (x, y) on the board.\n",
        "        Args:\n",
        "            x (float): X-coordinate of the position.\n",
        "            y (float): Y-coordinate of the position.\n",
        "            color (float): Color of the stone (1 for black, -1 for white).\n",
        "        \"\"\"\n",
        "        # TODO: change the method owing to the new board representation\n",
        "        if color == 1:  # black stone\n",
        "            self.board[0][x][y] = color\n",
        "        elif color == -1:  # white stone\n",
        "            self.board[1][x][y] = color\n",
        "        self.__remove_dead_stones(x, y, color)\n",
        "\n",
        "    def __has_liberties(self, board, x, y, color, visited, dead_stones):\n",
        "        \"\"\"\n",
        "        Checks if a stone at a given position has liberties.\n",
        "\n",
        "        Args:\n",
        "            board (torch.Tensor): Current game board.\n",
        "            x (int): X-coordinate of the position.\n",
        "            y (int): Y-coordinate of the position.\n",
        "            color (int): Color of the stone (1 for black, -1 for white).\n",
        "            visited (set): Set of visited positions to avoid infinite recursion (default is None).\n",
        "            no_liberties (set): Set of positions without liberties (default is None).\n",
        "\n",
        "        Returns:\n",
        "            tuple: (bool: True if the stone has liberties, False otherwise,\n",
        "                    set: Updated no_liberties set.)\n",
        "        \"\"\"\n",
        "        # TODO: change the method owing to the new board representation -- DONE\n",
        "        # TODO: check the correctness of the method -- DONE\n",
        "\n",
        "        # If the position has been visited before, return no liberties\n",
        "        if (x, y) in visited:\n",
        "            return False\n",
        "\n",
        "        # Mark the current position as visited\n",
        "        visited.add((x, y))\n",
        "\n",
        "        # Check if the position is out of the board bounds\n",
        "        if x < 0 or x >= len(board) or y < 0 or y >= len(board[0]):\n",
        "            return False\n",
        "\n",
        "        # If the position is empty, it has liberties\n",
        "        if board[0][x][y] == 0 and board[1][x][y] == 0:\n",
        "            return True\n",
        "\n",
        "        # If the stone at the position is not of the given color, it has no liberties\n",
        "        if board[0][x][y] != 1 and board[1][x][y] != -1:\n",
        "            return False\n",
        "\n",
        "        # Recursive check for liberties in adjacent positions\n",
        "        liberties = any(\n",
        "            self.__has_liberties(board, x + dx, y + dy, color, visited, dead_stones)\n",
        "            for dx, dy in [(1, 0), (-1, 0), (0, 1), (0, -1)]\n",
        "        )\n",
        "\n",
        "        # If the stone has no liberties, add it to the no_liberties set\n",
        "        if not liberties:\n",
        "            dead_stones.add((x, y))\n",
        "\n",
        "        return liberties\n",
        "\n",
        "    def __remove_dead_stones(self, x, y, color) -> None:\n",
        "        \"\"\"\n",
        "        Removes dead stones of the specified color from the board.\n",
        "\n",
        "        Args:\n",
        "            x (float): X-coordinate of the position.\n",
        "            y (float): Y-coordinate of the position.\n",
        "            color (float): Color of the stone (1 for black, -1 for white).\n",
        "        \"\"\"\n",
        "        # TODO: change the method owing to the new board representation\n",
        "        # TODO: check the correctness of the method\n",
        "\n",
        "        # Determine the opponent's color\n",
        "        opponent_color = -color\n",
        "\n",
        "        # Create a set to store positions of dead stones\n",
        "        dead_stones = set()\n",
        "\n",
        "        # Iterate through the neighboring positions\n",
        "        for dx, dy in [(1, 0), (-1, 0), (0, 1), (0, -1)]:\n",
        "            visited = set()\n",
        "            # Check if the neighboring stone has liberties\n",
        "            self.__has_liberties(\n",
        "                self.board, x + dx, y + dy, opponent_color, visited, dead_stones\n",
        "            )\n",
        "\n",
        "        # Remove dead stones from the board\n",
        "        for x, y in dead_stones:\n",
        "            self.board[0][x][y] = 0\n",
        "            self.board[1][x][y] = 0\n",
        "\n",
        "    def get_board(self) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Returns the current game board.\n",
        "        Returns:\n",
        "            torch.Tensor: Current game board.\n",
        "        \"\"\"\n",
        "        return self.board\n",
        "\n",
        "    def reset(self) -> None:\n",
        "        \"\"\"\n",
        "        Resets the game board to the initial state.\n",
        "        \"\"\"\n",
        "        self.board = torch.zeros(\n",
        "            2, self.board_size, self.board_size, dtype=torch.float32\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JNsscRqt6EZ"
      },
      "source": [
        "# define dataset for model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "Ldw0c2e6t6EZ",
        "outputId": "277494df-9a3a-44b8-b0ef-5e19bbac54e5"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class GoDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        \"\"\"\n",
        "        Initializes the GoDataset with the given CSV file path.\n",
        "        Args:\n",
        "            path (str): Path to the CSV file containing Go game data.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.path = path\n",
        "        self.goGame = GoGame()\n",
        "        self.char2idx = {c: i for i, c in enumerate('abcdefghijklmnopqrs')}\n",
        "\n",
        "        # Load data from CSV file\n",
        "        with open(self.path, newline='') as csvfile:\n",
        "            reader = csv.reader(csvfile, delimiter=',')\n",
        "            # Read row by row\n",
        "            self.data = list(reader)  # dtype: list[str]\n",
        "            # Discard the label and player turn information, calculate the max sequence length\n",
        "            self.max_sequence_length = max([len(row) for row in self.data]) - 2\n",
        "\n",
        "    def __step(self, step):\n",
        "        \"\"\"\n",
        "        Perform a step in the game based on the given input step.\n",
        "        Args:\n",
        "            step (str): A str containing player, x-coordinate, and y-coordinate information.\n",
        "        \"\"\"\n",
        "        # TODO???: change the method owing to the new board representation\n",
        "        current_player_color = torch.tensor([1.0]) if step[0] == 'B' else torch.tensor([-1.0])\n",
        "\n",
        "        x = self.char2idx[step[2]]\n",
        "        y = self.char2idx[step[3]]\n",
        "        self.goGame.place_stone(x, y, current_player_color.item())\n",
        "\n",
        "    def __transform(self, data):\n",
        "        \"\"\"\n",
        "        Transform data from CSV file into a list of padded boards.\n",
        "        Args:\n",
        "            data (list): List of steps in the game.\n",
        "        Returns:\n",
        "            torch.Tensor: Transformed and padded data.\n",
        "        \"\"\"\n",
        "        # TODO: change the method owing to the new board representation\n",
        "        # TODO: make a new method for rotating the board\n",
        "        # TODO: make a new method for truncating the data\n",
        "        # TODO: modify the return value to return a tuple (previous_board, current_board)\n",
        "\n",
        "        transformed_data = []\n",
        "        previous_board = None\n",
        "        for i in range(2, len(data)):\n",
        "            self.__step(data[i])\n",
        "            current_board = self.goGame.get_board().clone()\n",
        "\n",
        "            if previous_board is not None:\n",
        "                transformed_data.append((previous_board.clone(), current_board.clone()))\n",
        "\n",
        "\n",
        "            # Set the current board as the previous board for the next iteration\n",
        "            previous_board = current_board.clone()\n",
        "\n",
        "        return transformed_data\n",
        "        # Instead of a single padded_data tensor,\n",
        "        # we maintain a list called transformed_data to store tuples of previous and current board states.\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of samples in the dataset.\n",
        "        Returns:\n",
        "            int: Number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Get data at the given index.\n",
        "        Args:\n",
        "            idx (int): Index of the data sample.\n",
        "        Returns:\n",
        "            torch.Tensor: Processed and padded data sample.\n",
        "        \"\"\"\n",
        "        # Get data at the given index\n",
        "        row = self.data[idx]\n",
        "\n",
        "        # Transform data into a board\n",
        "        self.goGame.reset()\n",
        "        processed_data = self.__transform(row)\n",
        "        return processed_data\n",
        "\n",
        "\n",
        "goDataset = GoDataset('data/train/dan_train.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-s7j-e2t6Ea"
      },
      "source": [
        "# visualize game"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "21ADjKEht6Ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data: <built-in method item of Tensor object at 0x000002841DA309B0>, data type: <class 'builtin_function_or_method'>\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "bad operand type for unary -: 'builtin_function_or_method'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\「main_ipynb」的副本.ipynb 儲存格 8\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                 cv2\u001b[39m.\u001b[39mcircle(image, (col \u001b[39m*\u001b[39m \u001b[39m20\u001b[39m \u001b[39m+\u001b[39m \u001b[39m20\u001b[39m, row \u001b[39m*\u001b[39m \u001b[39m20\u001b[39m \u001b[39m+\u001b[39m \u001b[39m20\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m                            \u001b[39m8\u001b[39m, white, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# Draw a filled circle\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m image\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m boards \u001b[39m=\u001b[39m goDataset\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     image \u001b[39m=\u001b[39m draw_board(boards[i]\u001b[39m.\u001b[39mnumpy())\n",
            "\u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\「main_ipynb」的副本.ipynb 儲存格 8\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39m# Transform data into a board\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgoGame\u001b[39m.\u001b[39mreset()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m processed_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__transform(row)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mreturn\u001b[39;00m processed_data\n",
            "\u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\「main_ipynb」的副本.ipynb 儲存格 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m previous_board \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39mlen\u001b[39m(data)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__step(data[i])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     current_board \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgoGame\u001b[39m.\u001b[39mget_board()\u001b[39m.\u001b[39mclone()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mif\u001b[39;00m previous_board \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\「main_ipynb」的副本.ipynb 儲存格 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchar2idx[step[\u001b[39m2\u001b[39m]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchar2idx[step[\u001b[39m3\u001b[39m]]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoGame\u001b[39m.\u001b[39;49mplace_stone(x, y, current_player_color\u001b[39m.\u001b[39;49mitem)\n",
            "\u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\「main_ipynb」的副本.ipynb 儲存格 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39melif\u001b[39;00m color \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:  \u001b[39m# white stone\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboard[\u001b[39m1\u001b[39m][x][y] \u001b[39m=\u001b[39m color\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__remove_dead_stones(x, y, color)\n",
            "\u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\「main_ipynb」的副本.ipynb 儲存格 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39m# TODO: change the method owing to the new board representation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m# TODO: check the correctness of the method\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39m# Determine the opponent's color\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata: \u001b[39m\u001b[39m{\u001b[39;00mcolor\u001b[39m}\u001b[39;00m\u001b[39m, data type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(color)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m opponent_color \u001b[39m=\u001b[39m \u001b[39m-\u001b[39;49mcolor\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39m# Create a set to store positions of dead stones\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X10sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m dead_stones \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
            "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary -: 'builtin_function_or_method'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "\n",
        "def draw_board(board):\n",
        "    \"\"\"\n",
        "    Draws the Go board with stones based on the provided board configuration.\n",
        "    Args:\n",
        "        board (numpy.ndarray): 2D array representing the Go board (-1 for black stones, 1 for white stones, 0 for empty).\n",
        "    Returns:\n",
        "        numpy.ndarray: RGB image of the Go board with stones and grid lines.\n",
        "    \"\"\"\n",
        "    # TODO: change the method owing to the new board representation\n",
        "\n",
        "    # Create an RGB image (3 channels) with a green background\n",
        "    image = np.ones((20*20, 20*20, 3), dtype=np.uint8) * \\\n",
        "        173  # RGB value for green\n",
        "\n",
        "    # Draw lines for the board grid\n",
        "    for i in range(1, 20):\n",
        "        cv2.line(image, (i * 20, 20), (i * 20, 20*20 - 20),\n",
        "                 color=(0, 0, 0), thickness=1)\n",
        "        cv2.line(image, (20, i * 20), (20*20 - 20, i * 20),\n",
        "                 color=(0, 0, 0), thickness=1)\n",
        "\n",
        "    black = (0, 0, 0)  # RGB for black\n",
        "    white = (255, 255, 255)  # RGB for white\n",
        "    # Draw stones on the board\n",
        "    for row in range(19):\n",
        "        for col in range(19):\n",
        "            if board[0][row][col] == -1:  # Black stone                 ##\n",
        "                cv2.circle(image, (col * 20 + 20, row * 20 + 20),\n",
        "                           8, black, -1)  # Draw a filled circle\n",
        "            elif board[1][row][col] == 1:  # White stone                ##\n",
        "                cv2.circle(image, (col * 20 + 20, row * 20 + 20),\n",
        "                           8, white, -1)  # Draw a filled circle\n",
        "\n",
        "    return image\n",
        "\n",
        "boards = goDataset[0]\n",
        "for i in range(10):\n",
        "    image = draw_board(boards[i].numpy())\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    time.sleep(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXZTU912t6Ea"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "\n",
        "def save_as_video(boards):\n",
        "    \"\"\"\n",
        "    Saves a sequence of Go board states as a video file.\n",
        "    Args:\n",
        "        boards (list): List of 2D numpy arrays representing Go board states.\n",
        "    \"\"\"\n",
        "    # TODO: change the method owing to the new board representation\n",
        "\n",
        "    # Define the codec and create a VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for video format (MP4)\n",
        "    # VideoWriter(filename, codec, fps, frameSize)\n",
        "    video = cv2.VideoWriter('test.mp4', fourcc, 7,\n",
        "                            (20*20, 20*20))  # VideoWriter object\n",
        "\n",
        "    # Iterate through the list of board states and save them as frames in the video\n",
        "    for board in boards:\n",
        "        image = draw_board(board)  # Convert board state to an RGB image\n",
        "        video.write(image)  # Write the image as a frame in the video\n",
        "\n",
        "    # Release the VideoWriter object, finalizing the video creation\n",
        "    video.release()\n",
        "\n",
        "\n",
        "# boards = goDataset.__getitem__(0)\n",
        "# save_as_video(boards)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ld5YTRKt6Eb"
      },
      "source": [
        "# PredEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvLMlGTvt6Eb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class PredEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    PredNet encoder module.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): input dimension.\n",
        "        num_channels (int): number of depthwise convolution layer input channels.\n",
        "        depthwise_kernel_size (int): kernel size of depthwise convolution layer.\n",
        "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
        "        bias (bool, optional): indicates whether to add bias term to each convolution layer. (Default: ``False``)\n",
        "        use_group_norm (bool, optional): use GroupNorm rather than BatchNorm. (Default: ``False``)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        num_channels: int,\n",
        "        depthwise_kernel_size: int,\n",
        "        dropout: float = 0.0,\n",
        "        bias: bool = False,\n",
        "        use_group_norm: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if (depthwise_kernel_size - 1) % 2 != 0:\n",
        "            raise ValueError(\n",
        "                \"depthwise_kernel_size must be odd to achieve 'SAME' padding.\")\n",
        "\n",
        "        # Layer normalization for input\n",
        "        self.layer_norm = nn.LayerNorm(input_dim)\n",
        "\n",
        "        # Sequential layers: 1x1 Conv, GLU, Depthwise Conv, Normalization, Activation, 1x1 Conv, Dropout\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                input_dim,\n",
        "                2 * num_channels,\n",
        "                1,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "                bias=bias,\n",
        "            ),\n",
        "            nn.GLU(dim=1),\n",
        "            nn.Conv1d(\n",
        "                num_channels,\n",
        "                num_channels,\n",
        "                depthwise_kernel_size,\n",
        "                stride=1,\n",
        "                padding=(depthwise_kernel_size - 1) // 2,\n",
        "                groups=num_channels,\n",
        "                bias=bias,\n",
        "            ),\n",
        "            nn.GroupNorm(num_groups=1, num_channels=num_channels)\n",
        "            if use_group_norm\n",
        "            else nn.BatchNorm1d(num_channels),\n",
        "            nn.SiLU(),  # SiLU activation function (Sigmoid Linear Unit)\n",
        "            nn.Conv1d(\n",
        "                num_channels,\n",
        "                input_dim,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "                bias=bias,\n",
        "            ),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of the Conformer convolution module.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Input tensor with shape `(B, D)`.\n",
        "            B: Batch size, D: Input dimension\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with shape `(B, D)`.\n",
        "        \"\"\"\n",
        "        # input: (B, D) -> (B, 1, D)\n",
        "        x = input.unsqueeze(1)\n",
        "        x = self.layer_norm(x)\n",
        "\n",
        "        # x: (B, 1, D) -> (B, D, 1)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.sequential(x)\n",
        "\n",
        "        return x.squeeze(2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4gmXVh5t6Eb"
      },
      "source": [
        "# conformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A240kPrFt6Eb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ConvModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Conformer convolution module.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): input dimension.\n",
        "        num_channels (int): number of depthwise convolution layer input channels.\n",
        "        depthwise_kernel_size (int): kernel size of depthwise convolution layer.\n",
        "        dropout (float, optional): dropout probability. (Default: 0.0)\n",
        "        bias (bool, optional): indicates whether to add bias term to each convolution layer. (Default: ``False``)\n",
        "        use_group_norm (bool, optional): use GroupNorm rather than BatchNorm. (Default: ``False``)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        num_channels: int,\n",
        "        depthwise_kernel_size: int,\n",
        "        dropout: float = 0.0,\n",
        "        bias: bool = False,\n",
        "        use_group_norm: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if (depthwise_kernel_size - 1) % 2 != 0:\n",
        "            raise ValueError(\n",
        "                \"depthwise_kernel_size must be odd to achieve 'SAME' padding.\")\n",
        "\n",
        "        # Layer normalization for input\n",
        "        self.layer_norm = nn.LayerNorm(input_dim)\n",
        "\n",
        "        # Sequential layers: 1x1 Conv, GLU, Depthwise Conv, Normalization, Activation, 1x1 Conv, Dropout\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                input_dim,\n",
        "                2 * num_channels,\n",
        "                1,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "                bias=bias,\n",
        "            ),\n",
        "            nn.GLU(dim=1),\n",
        "            nn.Conv1d(\n",
        "                num_channels,\n",
        "                num_channels,\n",
        "                depthwise_kernel_size,\n",
        "                stride=1,\n",
        "                padding=(depthwise_kernel_size - 1) // 2,\n",
        "                groups=num_channels,\n",
        "                bias=bias,\n",
        "            ),\n",
        "            nn.GroupNorm(num_groups=1, num_channels=num_channels)\n",
        "            if use_group_norm\n",
        "            else nn.BatchNorm1d(num_channels),\n",
        "            nn.SiLU(),  # SiLU activation function (Sigmoid Linear Unit)\n",
        "            nn.Conv1d(\n",
        "                num_channels,\n",
        "                input_dim,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "                bias=bias,\n",
        "            ),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of the Conformer convolution module.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Input tensor with shape `(B, T, D)`.\n",
        "            B: Batch size, T: Sequence length, D: Input dimension\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with shape `(B, T, D)`.\n",
        "        \"\"\"\n",
        "        x = self.layer_norm(input)\n",
        "        # Transpose to shape `(B, D, T)` for 1D convolutions\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.sequential(x)  # Apply sequential layers\n",
        "        return x.transpose(1, 2)  # Transpose back to shape `(B, T, D)`\n",
        "\n",
        "\n",
        "class FeedForwardModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Feedforward module with Layer Normalization, Linear layers, SiLU activation, and Dropout.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Input dimension.\n",
        "        hidden_dim (int): Hidden layer dimension.\n",
        "        dropout (float, optional): Dropout probability. (Default: 0.1)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
        "        super(FeedForwardModule, self).__init__()\n",
        "        self.module = nn.Sequential(\n",
        "            nn.LayerNorm(input_dim),\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.SiLU(),  # SiLU activation function (Sigmoid Linear Unit)\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, input_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the FeedForwardModule.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape `(B, T, D)`.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with the same shape as the input tensor.\n",
        "        \"\"\"\n",
        "        return self.module(x)\n",
        "\n",
        "\n",
        "class ConformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Conformer layer that constitutes Conformer.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): input dimension.\n",
        "        ffn_dim (int): hidden layer dimension of the feedforward network.\n",
        "        num_attention_heads (int): number of attention heads.\n",
        "        depthwise_conv_kernel_size (int): kernel size of the depthwise convolution layer.\n",
        "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
        "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
        "            in the convolution module. (Default: ``False``)\n",
        "        convolution_first (bool, optional): apply the convolution module ahead of\n",
        "            the attention module. (Default: ``False``)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim,\n",
        "            ffn_dim,\n",
        "            num_attention_heads,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout=0.1,\n",
        "            use_group_norm=False,\n",
        "            convolution_first=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.ffn1 = FeedForwardModule(input_dim, ffn_dim, dropout)\n",
        "        self.ffn2 = FeedForwardModule(input_dim, ffn_dim, dropout)\n",
        "        self.conv = ConvModule(\n",
        "            input_dim,\n",
        "            input_dim,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout,\n",
        "            use_group_norm=use_group_norm,\n",
        "        )\n",
        "        self.self_attn = nn.MultiheadAttention(\n",
        "            input_dim, num_attention_heads, dropout=dropout\n",
        "        )\n",
        "        self.self_attn_dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(input_dim)\n",
        "        self.convolution_first = convolution_first\n",
        "\n",
        "    def __apply_conv(self, x):\n",
        "        \"\"\"\n",
        "        Apply the convolution module.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape `(T, B, D)`.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after applying the convolution module.\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        # Transpose to shape `(B, T, D)` for 1D convolutions\n",
        "        x = x.transpose(0, 1)\n",
        "        x = self.conv(x)\n",
        "        x = x.transpose(0, 1)  # Transpose back to shape `(T, B, D)`\n",
        "        x = x + residual\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the ConformerBlock.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape `(T, B, D)`.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with the same shape as the input tensor.\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        x = self.ffn1(x)  # First feedforward module\n",
        "        x = 0.5 * x + residual  # Residual connection and scaling\n",
        "\n",
        "        if self.convolution_first:\n",
        "            x = self.__apply_conv(x)  # Apply convolution module if specified\n",
        "\n",
        "        residual = x\n",
        "        x = self.layer_norm(x)  # Layer normalization\n",
        "        x, _ = self.self_attn(x, x, x)  # Multihead self-attention\n",
        "        x = self.self_attn_dropout(x)\n",
        "        x = x + residual  # Residual connection\n",
        "\n",
        "        if not self.convolution_first:\n",
        "            x = self.__apply_conv(x)  # Apply convolution module if specified\n",
        "\n",
        "        residual = x\n",
        "        x = self.ffn2(x)  # Second feedforward module\n",
        "        x = 0.5 * x + residual  # Residual connection and scaling\n",
        "        x = self.layer_norm(x)  # Final layer normalization\n",
        "        return x\n",
        "\n",
        "\n",
        "class Conformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        input_dim (int): input dimension.\n",
        "        num_heads (int): number of attention heads in each Conformer layer.\n",
        "        ffn_dim (int): hidden layer dimension of feedforward networks.\n",
        "        num_layers (int): number of Conformer layers to instantiate.\n",
        "        depthwise_conv_kernel_size (int): kernel size of each Conformer layer's depthwise convolution layer.\n",
        "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
        "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
        "            in the convolution module. (Default: ``False``)\n",
        "        convolution_first (bool, optional): apply the convolution module ahead of\n",
        "            the attention module. (Default: ``False``)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim,\n",
        "            num_heads,\n",
        "            ffn_dim,\n",
        "            num_layers,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout=0.1,\n",
        "            use_group_norm=False,\n",
        "            convolution_first=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Instantiate Conformer blocks\n",
        "        self.conformer_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConformerBlock(\n",
        "                    input_dim,\n",
        "                    ffn_dim,\n",
        "                    num_heads,\n",
        "                    depthwise_conv_kernel_size,\n",
        "                    dropout,\n",
        "                    use_group_norm,\n",
        "                    convolution_first,\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the Generator (Conformer model).\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input with shape `(B, T, input_dim)`.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: output with shape `(B, T, input_dim)`.\n",
        "        \"\"\"\n",
        "        batch_size, seq_length, _, _ = x.shape\n",
        "        x = x.view(batch_size, seq_length, -1)  # Flatten input tensor\n",
        "\n",
        "        x = x.transpose(0, 1)  # Transpose to shape `(T, B, input_dim)`\n",
        "\n",
        "        # Pass input through Conformer blocks\n",
        "        for layer in self.conformer_blocks:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = x.transpose(0, 1)  # Transpose back to shape `(B, T, input_dim)`\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvYQZDqlt6Ec"
      },
      "source": [
        "# generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThiEOUFjt6Ec"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    Model: Conformer\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): input dimension.\n",
        "        output_dim (int): output dimension.\n",
        "        num_heads (int): number of attention heads in each Conformer layer.\n",
        "        ffn_dim (int): hidden layer dimension of feedforward networks.\n",
        "        num_layers (int): number of Conformer layers to instantiate.\n",
        "        depthwise_conv_kernel_size (int): kernel size of each Conformer layer's depthwise convolution layer.\n",
        "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
        "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
        "            in the convolution module. (Default: ``False``)\n",
        "        convolution_first (bool, optional): apply the convolution module ahead of\n",
        "            the attention module. (Default: ``False``)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim,\n",
        "            output_dim,\n",
        "            num_heads,\n",
        "            ffn_dim,\n",
        "            num_layers,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout=0.1,\n",
        "            use_group_norm=False,\n",
        "            convolution_first=False,\n",
        "    ):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Instantiate the Conformer module\n",
        "        self.conformer = Conformer(\n",
        "            input_dim,\n",
        "            num_heads,\n",
        "            ffn_dim,\n",
        "            num_layers,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout,\n",
        "            use_group_norm,\n",
        "            convolution_first,\n",
        "        )\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the Generator (Conformer model).\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input with shape `(B, T, input_dim)`.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: output with shape `(B, output_dim)`.\n",
        "        \"\"\"\n",
        "        input_copy = torch.clone(x)\n",
        "\n",
        "        # Pass the input through the Conformer layers\n",
        "        conformer_output = self.conformer(x)\n",
        "\n",
        "        # Reshape the output for the linear layer\n",
        "        B, T, D = conformer_output.shape\n",
        "        reshaped_output = conformer_output.reshape(B, T * D)\n",
        "\n",
        "        # Apply linear transformation\n",
        "        linear_output = nn.Linear(\n",
        "            reshaped_output.shape[1], self.output_dim)(reshaped_output)\n",
        "        # Apply log softmax activation\n",
        "        output = nn.LogSoftmax(dim=1)(linear_output)\n",
        "        # nn.crossEntropyLoss() expects the output to be of shape (B, output_dim)\n",
        "\n",
        "        return output, input_copy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nonwRQIzt6Ed"
      },
      "source": [
        "# discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPxQ5aI2t6Ed"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Model: Conformer, PredEncoder\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): input dimension for Conformer.\n",
        "        num_heads (int): number of attention heads in each Conformer layer.\n",
        "        ffn_dim (int): hidden layer dimension of feedforward networks in Conformer.\n",
        "        num_layers (int): number of Conformer layers to instantiate.\n",
        "        depthwise_conv_kernel_size (int): kernel size of each Conformer layer's depthwise convolution layer.\n",
        "        dropout (float, optional): dropout probability. (Default: 0.1)\n",
        "        use_group_norm (bool, optional): use ``GroupNorm`` rather than ``BatchNorm1d``\n",
        "            in the convolution module. (Default: ``False``)\n",
        "        convolution_first (bool, optional): apply the convolution module ahead of\n",
        "            the attention module. (Default: ``False``)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim,\n",
        "            num_heads,\n",
        "            ffn_dim,\n",
        "            num_layers,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout=0.1,\n",
        "            use_group_norm=False,\n",
        "            convolution_first=False,\n",
        "    ):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Instantiate the Generator (Conformer) module\n",
        "        self.generator = Generator(\n",
        "            input_dim,\n",
        "            input_dim,\n",
        "            num_heads,\n",
        "            ffn_dim,\n",
        "            num_layers,\n",
        "            depthwise_conv_kernel_size,\n",
        "            dropout,\n",
        "            use_group_norm,\n",
        "            convolution_first,\n",
        "        )\n",
        "\n",
        "        # Instantiate the PredEncoder module\n",
        "        self.pred_encoder = PredEncoder(\n",
        "            input_dim=input_dim,\n",
        "            num_channels=input_dim,\n",
        "            depthwise_kernel_size=3,\n",
        "            bias=False,\n",
        "            use_group_norm=False,\n",
        "        )\n",
        "\n",
        "        # Linear layers for final classification\n",
        "        self.linear = nn.Sequential(\n",
        "            # Concatenate Conformer output and PredEncoder output\n",
        "            nn.Linear(2 * input_dim, input_dim // 2),\n",
        "            nn.BatchNorm1d(input_dim // 2),\n",
        "            nn.SiLU(),\n",
        "            # Output one-hut vector for binary classification\n",
        "            nn.Linear(input_dim // 2, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        \"\"\"\n",
        "        Forward pass of the Discriminator.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input with shape `(B, T, input_dim)` (for Conformer).\n",
        "            y (torch.Tensor): input with shape `(B, height * width)` (for PredEncoder).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: output with shape `(B, 2)` (binary classification result).\n",
        "        \"\"\"\n",
        "        # Pass the input through the Conformer (Generator) layers\n",
        "        x, _ = self.generator(x)\n",
        "        # Pass the input through the PredEncoder\n",
        "        # G(x) or ground truth y or ground truth with wrong cond\n",
        "        y = self.pred_encoder(y)\n",
        "\n",
        "        # Concatenate Conformer output and PredEncoder output\n",
        "        x = torch.cat((x, y), dim=1)\n",
        "\n",
        "        # Apply linear transformation for final classification\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7m4t4sxt6Ed"
      },
      "source": [
        "# models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX_cbZ5_t6Ed"
      },
      "outputs": [],
      "source": [
        "height, width = 19, 19\n",
        "\n",
        "gen = Generator(\n",
        "    input_dim=height * width,\n",
        "    output_dim=height * width,\n",
        "    num_heads=1,\n",
        "    ffn_dim=8,\n",
        "    num_layers=6,\n",
        "    depthwise_conv_kernel_size=3,\n",
        "    dropout=0.1,\n",
        "    use_group_norm=False,\n",
        "    convolution_first=False,\n",
        ")\n",
        "\n",
        "\n",
        "dis = Discriminator(\n",
        "    input_dim=height * width,\n",
        "    num_heads=1,\n",
        "    ffn_dim=8,\n",
        "    num_layers=6,\n",
        "    depthwise_conv_kernel_size=3,\n",
        "    dropout=0.1,\n",
        "    use_group_norm=False,\n",
        "    convolution_first=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzgsjluht6Ed"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt5GjUcJt6Ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch size: 50\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "bad operand type for unary -: 'builtin_function_or_method'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\「main_ipynb」的副本.ipynb 儲存格 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbatch size: \u001b[39m\u001b[39m{\u001b[39;00mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m idx, batch \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(test_loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtime for \u001b[39;49m\u001b[39m{\u001b[39;49;00midx\u001b[39m}\u001b[39;49;00m\u001b[39mth data preprocessing: \u001b[39;49m\u001b[39m{\u001b[39;49;00mtime\u001b[39m.\u001b[39;49mtime()\u001b[39m \u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m \u001b[39;49mstart\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39;49m(batch\u001b[39m.\u001b[39;49mshape)\n",
            "File \u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "\u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\「main_ipynb」的副本.ipynb 儲存格 21\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39m# Transform data into a board\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgoGame\u001b[39m.\u001b[39mreset()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m processed_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__transform(row)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mreturn\u001b[39;00m processed_data\n",
            "\u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\「main_ipynb」的副本.ipynb 儲存格 21\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m previous_board \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39mlen\u001b[39m(data)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__step(data[i])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     current_board \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgoGame\u001b[39m.\u001b[39mget_board()\u001b[39m.\u001b[39mclone()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mif\u001b[39;00m previous_board \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\「main_ipynb」的副本.ipynb 儲存格 21\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchar2idx[step[\u001b[39m2\u001b[39m]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchar2idx[step[\u001b[39m3\u001b[39m]]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoGame\u001b[39m.\u001b[39;49mplace_stone(x, y, current_player_color\u001b[39m.\u001b[39;49mitem)\n",
            "\u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\「main_ipynb」的副本.ipynb 儲存格 21\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39melif\u001b[39;00m color \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:             \u001b[39m#white stone\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboard[\u001b[39m1\u001b[39m][x][y] \u001b[39m=\u001b[39m color\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__remove_dead_stones(x, y, color)\n",
            "\u001b[1;32md:\\Programming\\Python\\Machine Learning\\Go\\「main_ipynb」的副本.ipynb 儲存格 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mRemoves dead stones of the specified color from the board.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m    color (float): Color of the stone (1 for black, -1 for white).\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39m# TODO: change the method owing to the new board representation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m# TODO: check the correctness of the method\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39m# Determine the opponent's color\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m opponent_color \u001b[39m=\u001b[39m \u001b[39m-\u001b[39;49mcolor\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m \u001b[39m# Create a set to store positions of dead stones\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Programming/Python/Machine%20Learning/Go/%E3%80%8Cmain_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb#X26sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m dead_stones \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
            "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary -: 'builtin_function_or_method'"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "test_loader = DataLoader(goDataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(f'batch size: {batch_size}')\n",
        "start = time.time()\n",
        "for idx, batch in enumerate(test_loader):\n",
        "    print(f'time for {idx}th data preprocessing: {time.time() - start}')\n",
        "    print(batch.shape)\n",
        "    with torch.no_grad():\n",
        "        output, input_copy = gen(batch)\n",
        "        print(output.shape)\n",
        "        output = dis(input_copy, output)\n",
        "        print(output.shape)\n",
        "\n",
        "    start = time.time()\n",
        "    if idx == 2:\n",
        "        break\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
